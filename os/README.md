# 운영체제 (OS – Operating System)
 - 컴퓨터 시스템의 자원들의 효율적 관리
 - 사용자가 컴퓨터를 편리, 효과적으로 사용할 수 있는 환경을 제공
 - 사용자와 하드웨어 사이의 인터페이스로서 동작하는 시스템 소프트웨어의 일종
 - 다른 응용프로그램이 유용한 작업을 할 수 있는 환경을 제공

## 운영체제의 목적은 무엇일까? (4가지가 존재) - 효율적
 - 처리능력 : 일정 시간 내에 시스템이 처리하는 일의 양
 - 반환시간(응답시간) : 시스템에 작업을 의뢰한 시간부터 처리 완료까지 걸린 시간
 - 사용 가능도 : 시스템을 사용할 필요가 있을 때 즉시 사용 가능한 정도
 - 신뢰도 : 시스템이 주어진 문제를 정확하게 해결하는 정도
이러한 네가지 목적이 운영체제의 성능을 평가하는 기준이 됨
![image](https://user-images.githubusercontent.com/97201374/181484365-b508446a-a806-407f-a292-c8ff167851ab.png)



## 운영체제는 자원관리도 해준다
 - 프로세스 관리 : 프로세스 스케줄링 및 동기화
		: 프로세스 생성과 제거, 시작과 정지, 메시지 전달
 - 기억장치 관리 : 프로세스에게 메모리 할당 및 회수
 - 주변장치 관리 : 입출력 장치 스케줄링 및 전반적인 관리
 - 파일 관리 : 파일의 생성과 삭제, 변경, 유지 등

 ＊ 운영체제는 두 가지로 나눠 생각할 수 있다
1. 제어프로그램 (Control Program)
 - 컴퓨터 내의 정보와 자원을 감시
 - 컴퓨터 내에서 실행하는 과정을 지시하고 관리

감시 프로그램 ◆
시스템 전체의 동작 상태를 감독하고 지원함
제어프로그램의 중추적 역할을 담당
모든 동작을 관리 감독하는 제어프로그램을 (슈퍼바이저)라고 한다
작업 관리 프로그램 ◆ 
어떤 작업을 처리하고 다른 작업으로의 자동적 이행을 수행
데이터 관리 프로그램 ◆
주기억 장치와 외부 보조 기억 장치 사이의 데이터 전송
입출력 데이터와 프로그램의 논리적 연결, 파일 조작 및 처리 담당


2. 처리프로그램 (Process Program)
 - 제어프로그램의 지시와 감독을 받아서
 - 실제로 데이터 처리를 실행하고 결과를 보여줌

언어 번역 프로그램 ◆ 
원시 프로그램을 컴퓨터가 알 수 있는 기계어로 번역시키는 프로그램
 - 컴파일러, 어셈블러, 인터프리터 등
서비스 프로그램 ◆
시스템에서 사용 빈도가 높은 프로그램을 미리 개발
 - 연계 편집 프로그램, 로더, 디버깅 프로그램, 정렬 / 병합 프로그램, 라이브러리 등
문제 처리 프로그램 ◆ 
컴퓨터 사용자가 필요한 업무에 맞게 개발한 프로그램
 - 급여 관리, 인사 관리, 회계 관리 등



OS를 가장 단순하게 생각한다면
<< 컴퓨터 하드웨어를 몰라도 쉽게 프로그램을 만들고 사용할 수 있게 만드는 것 >>


# 프로세스 (Process)

프로세스란 하나의 작업 단위로 같은 용어로 태스크(Task)라고도 함

운영체제가 프로그램을 메모리의 적당한 위치로 가져오면
가져옴과 동시에 프로세스 제어 블록 (Process Control Block, PCB)를 만드는데,
이 PCB 내에 프로세스를 실행하기 위한 다양한 정보가 들어있다.

즉, 어떤 프로그램이 프로세스가 되었다 라는 말은
운영체제로부터 프로세스 제어블록을 받았다
![image](https://user-images.githubusercontent.com/97201374/181484583-de534af9-778b-4a9d-b71d-7d94702be48c.png)



## 프로세스란 무엇인가?
 - 운영체제에서 실행중인 하나의 애플리케이션을 칭한다
 - 사용자가 프로그램을 실행하면 운영체제로부터 실행에 필요한 메모리를 할당받아 애플리케이션의 코드를 실행
 - 프로세스란 이때 실행되는 애플리케이션을 말한다.

또한, 프로그램은 다중 프로세스를 만들기도 한다.
ex) 인터넷 브라우저 두 개 실행 시, 두 개의 프로세스가 생성된다
 - 이처럼 하나의 애플리케이션은 다중 프로세스를 만들기도 한다.

확인하는 방법
(Mac OS에서 활성 상태 보기 / Windows에서 작업관리자)

![image](https://user-images.githubusercontent.com/97201374/181484615-4825b632-5857-4443-a3a2-964d8b8c84e2.png)



## 프로세스의 상태

![image](https://user-images.githubusercontent.com/97201374/181484653-78e3f7cc-dbe6-43d4-adfb-1125e957ea62.png)


1. 생성 (create) : 프로세스가 메모리에 올라와 실행준비를 완료한 상태
 - 프로세스를 관리하는데 필요한 PCB 생성 
2. 준비 (ready) : 생성된 프로세스가 CPU를 얻을 때까지 기다리는 상태
 - CPU가 하나인 컴퓨터에서는 한 번에 하나의 프로세스만 실행하기 때문에, 실행 순서가 될 때까지 준비 상태로 기다려야 함
3. 실행 (running) : 준비 상태에 있는 프로세스 중 하나가 CPU를 얻어 실제 작업을 수행
 - 실행 상태에 들어간 프로세스는 일정 시간 CPU 사용할 권리를 갖는다
 - 주어진 시간 내에 작업을 끝마치지 못할 경우에 준비 상태로 돌아와 다음 차례를 기다림
4. 완료 (terminate) : 프로세스가 작업을 마친 상태
 - PCB 블록이 메모리에서 제거된 상태
5. 대기상태 (blocking) : 입출력을 요청한 프로세스를 실행 상태에 두지 않고 대기 상태로 옮긴 것
 - 작업의 효율성을 높이기 위함
 - 대기 상태로 옮겨질 경우 다른 준비 상태의 프로세스를 가져와 실행
 - 대기 상태의 프로세스는 요청한 입출력 완료 시 관리자로부터 인터럽트를 받는다
 - 인터럽트를 받은 프로세스는 준비상태로 이동, 자신의 순서에 맞게 작업 진행
 
 ![image](https://user-images.githubusercontent.com/97201374/181484686-2fabcbad-8e8e-4d51-9970-a180d6337465.png)


6. 휴식상태 (pause) : 프로세스가 일시적으로 작업을 쉬고 있는 상태
 - 사용하던 데이터가 메모리에 그대로 남아있음
 - PCB도 그대로 유지
 - 프로세스는 멈춘 상태로 유지되며 재시작 할 수 있다
 - 잠시 중지되어있다가 다시 ready 상태로 돌아옴
7. 보류상태 (suspend) : 프로세스가 메모리에서 잠시 쫓겨난 상태
 - 컴퓨터의 성능을 떨어뜨리는 경우
 - 실행 미뤄두어도 큰 지장이 발생하지 않는 경우
 - 데이터에 메모리가 남아있지 않음 (스왑 영역에 보관)
 - 잠시 중지되어있다가 누군가 재개시켜줘야 ready 상태로 돌아옴

## 프로세스 복사
 - 커널에서 제공되는 fork( ) 함수를 이용하여 실행 중인 프로세스로부터 새로운 프로세스를 복사
 - 프로세스 생성보다 속도가 빠르다
 - 부모-자식의 관계 성립으로 추가 작업 없이 자원을 상속
 - 부모-자식의 관계로 프로세스 완료 후 정리작업을 부모에게 넘겨 시스템 관리가 효율적

## 프로세스 제어 블록 PCB

운영체제가 프로세스를 제어하기 위해 정보를 저장해놓은 곳으로
프로세스의 상태정보를 저장하는 구조체라고 생각하면 편하다

프로세스 상태 관리와 문맥 교환을 위해 필요한 것이라고 생각
PCB가 중요한 정보를 포함하고 있기 때문입니다.


## PCB 블록의 구조
 -  프로세스 식별번호 (Process IDentification) : 운영체제가 각 프로세스를 식별하기 위해 부여한 번호
 - 프로세스 상태 : CPU는 프로세스를 빠르게 교체하면서 실행하기 때문에 이러한 프로세스의 상태를 저장한다
 - 프로그램 카운터 : CPU가 다음으로 실행할 명령어를 가리키는 값
 - 스케줄링 우선순위 : 운영체제의 여러 프로세스가 CPU에서 실행되는 순서를 정하는 것
 - 권한 : 프로세스가 접근할 수 있는 자원을 결정하는 정보
 - 프로세스의 부모-자식 : 최초 생성 init 프로세스를 제외하고 모든 프로세스는 부모 프로세스를 복사해서 생성, 이 계층 관계는 트리를 형성 (각 프로세스는 부모-자식의 정보를 가짐)
 - 포인터 : 프로세스의 데이터와 명령어가 있는 메모리 위치를 가리킴
 - 실행 문맥 : 프로세스는 실행 상태에서 마지막 실행한 프로세서의 레지스터를 담고 있음 

PCB의 관리 방식
 - Linked List 방식으로 관리
 - PCB List Head에 PCB들이 생성될 때마다 붙게 된다.
 - 주소값으로 List에 연결이 되기 때문에 삽입, 삭제가 용이하다

PCB의 문맥 교환 (Context Switching)
 - CPU를 차지하던 프로세스가 나가고 새로운 프로세스를 받아들이는 작업

![image](https://user-images.githubusercontent.com/97201374/181484730-e5aa3a66-d4f5-4b7c-b842-886a0cf361d9.png)


문맥 교환 발생 상황 (4가지)
 - 입출력 요청 : I/O request
 - CPU 사용시간 만료 : time slice expired
 - 자식 프로세스 생성 : fork a child
 - 인터럽트 처리 대기 : wait for an interrupt

문맥 교환을 진행하는 과정에서 발생하는 시간과 메모리를
Context Switching Overhead라고 부름

문맥 교환 시 해당 CPU가 아무런 일을 하지 못하기 때문에
문맥 교환이 잦아지면 오버헤드가 발생해 효율이 떨어질 수 있다.


## 스레드 (Thread)
 - 프로세스 안에서 한 가지 작업을 실행하기 위해 순차적으로 실행되는 하나의 흐름
 - 한 가지 작업을 실행하기 위해 순차적으로 실행한 코드를 실처럼 이어 놓았다고 생각
 - 하나의 스레드 = 코드에 실행되는 하나의 흐름
 - 두 개의 스레드 = 코드에 실행되는 두 개의 흐름

![image](https://user-images.githubusercontent.com/97201374/181484762-66d0f71d-ba7d-4edf-9434-d16deb134023.png)


스레드의 종류 (싱글 스레드 / 멀티 스레드)
### 싱글 스레드 (Single Thread)
 - 하나의 프로그램에서 동시에 하나의 코드만 실행할 수 있다
 - 코드가 실행되서 끝난 지점과 다음 코드의 시작 지점이 연결된 형태
 - 각 스레드는 한 번에 하나의 작업만 수행할 수 있다
 - 각 작업은 순차적으로 실행
(Task A – Task B – Task C ....)

### 멀티 스레드 (Multi Thread)
 - 애플리케이션 내부에서의 멀티 태스킹으로 생각
 - 대용량 데이터 처리시간을 줄이기 위해 멀티스레드 사용
(데이터를 분할하여 병렬로 처리함)
 - UI를 가지고 있는 애플리케이션에서 네트워크 통신 이용
 - 여러 클라이언트의 요청을 처리하는 서버 개발에서도 사용

 - 하나의 프로세스 내에서 멀티 스레드로 두 가지 이상의 작업을 처리할 수 있음
 - 멀티 스레드를 지원하는 애플리케이션은 여러 코어를 사용
 - 동시에 여러 작업을 완료할 수 있다
 - 동시에 작업할 수 있는 스레드 수는 컴퓨터 코어 수로 제한된다
(Thread 1 : Task A – Task B)
(Thread 2 : Task C – Task D)


## 멀티 스레딩의 장단점
1. 장점
 - 응답성 : 프로그램의 일부분(스레드)이 중단되거나 긴 작업을 수행하더라도 프로그램의 수행이 계속되어 사용자의 응답성이 증가한다
 - 경제성 : 프로세스 내 자원들과 메모리를 공유하기 때문에 메모리 공간과 시스템 자원 소모가 줄어든다
	: 스레드 간 통신이 필요한 경우에도 쉽게 데이터를 주고받을 수 있으며, 스레드 사이의 문맥교환은 캐시메모리를 비울 필요가 없어 속도가 더 빠르다
 - 멀티프로세서 활용 : 다중 CPU 구조에서는 각각의 스레드가 다른 프로세서에서 병렬로 수행될 수 있으므로 병렬성이 증가한다

2. 단점
 - 임계 영역(Critical Section) : 둘 이상의 스레드를 동시에 실행하면 문제를 일으키는 코드 블록
 - 공유 자원에 동시에 접근하는 경우, 스레드는 데이터와 힙 영역을 공유하기 때문에 다른 스레드에서 사용 중인 변수나 다른 값을 읽어올 가능성이 존재
 - 동기화가 필요 : 동기화를 통해 스레드 작업 처리 순서와 공유 자원에 대한 접근을 컨트롤 할 수 있다
 - 단일 스레드보다 느릴 수 있음 : 문맥 교환, 동기화 등의 이유로 인해 싱글 코어 멀티 스레딩은 스레드 생성 시간이 오버헤드로 작용하기 때문


## 멀티 스레드 vs 멀티 프로세스
 - 멀티 스레드 : 멀티 프로세스보다 작은 메모리공간을 차지
		: 문맥 교환이 빠른 장점이 존재
		: 동기화 문제와 하나의 스레드 장애로 전체 스레드가 종료될 위험을 가짐
 - 멀티 프로세스 : 하나의 프로세스가 죽더라도 아늘 프로세스에 영향을 주지 않아 안정
		: 멀티 스레드보다 많은 메모리 공간과 CPU 시간을 차지
멀티 스레드와 멀티 프로세스는 동시에 여러 작업을 수행한다는 점에서 동일하지만, 각각의 장단점이 있기에 적용하는 시스템에 따라 적합한 동작 방식을 선택하고 적용해야 함

## 스케줄러 (Scheduler)
어떤 프로세스에게 자원을 할당할지를 결정하는 운영체제 커널의 모듈을 지칭
스케줄러에 따라서 프로세스 상태도 바뀌게 된다
프로세스들은 자신이 종료될 때까지 수많은 큐 안을 떠돌아다닌다
이 때, OS는 큐 안에 있는 프로세스 중 하나를 선택해야 함 이를 스케줄러라 함
한정적 메모리를 여러 프로세스가 효율적으로 사용할 수 있도록 다음 실행할 프로세스를 선택
1. Scheduling Queues : 프로세스를 관리하는 큐
2. Job Queue : 시스템 안의 모든 프로세스의 집합
3. Ready Queue : ready 상태의 메인메모리 안에 상주하는 모든 프로세스의 집합 
		: CPU를 잡아 실행되기를 기다리는 프로세스의 집합
4. Device Queue : I/O 장치 사용을 대기하는 프로세스들의 집합

### 좋은 스케줄링 방식 판단 기준
 - CPU utilization (CPU 사용률)
 - Throughput (처리율 – 단위 시간당 디지털 데이터 전송 처리 양)
 - Turnaround time (소요시간)
 - Wating time (대기시간)
 - response time (응답시간)


## Queue에 프로세스들을 넣고 빼주는 스케줄러 세 가지
1. 장기 스케줄러 = 잡 스케줄러
- 메모리는 한정되어있는데 많은 프로세스들이 한꺼번에 메모리에 올라올 경우, 대용량 메모리에 임시로 저장
-  이 pool에 저장되어있는 프로세스 중 어떤 프로세스에 메모리를 할당하여 ready queue로 보낼지 결정하는 역할을 함
☞ 메모리와 디스크 사이의 스케줄링을 담당
☞ 프로세스에 메모리 및 각종 리소스를 할당
☞ degree of Multiprogramming 제어 : 메모리에 몇 개의 프로그램이 올라갈 것인지 제어
☞ 프로세스의 상태 변경 new → ready

2. 단기 스케줄러 = CPU 스케줄러
☞ CPU와 메모리 사이의 스케줄링을 담당
☞ Ready Queue에 존재하는 프로세스 중 어떤 프로세스를 running으로 전환 시킬지 결정
☞ 프로세스에 CPU를 할당 (scheduler dispatch)
☞ 프로세스의 상태 변경 ready → running → waiting → ready

3. 중기 스케줄러 = 스와퍼
☞ 여유 공간 마련을 위해 프로세스를 통째로 메모리에서 디스크로 쫓아냄 (swapping)
☞ 프로세스에게서 메모리를 deallocate
☞ degree of Multiprogramming 제어
☞ 현 시스템에서 메모리에 너무 많은 프로그램이 동시에 올라가는 것을 조절
☞ 프로세스의 상태 변경 ready → suspended

＊ 스케줄링 알고리즘 (Scheduling Algorithm)
스케줄링 대상은 Ready Queue에 있는 프로세스들이다



FCFS
(First Come First Served)
◆ 특징
☞ 먼저 온 고객을 먼저 처리해주는 방식, 순서대로 처리
☞ 비선점형 스케줄링
☞ CPU가 선정된 후 CPU burst가 완료될 때까지 반환하지 않는다
☞ 할당되었던 CPU가 반환될 때만 스케줄링이 이뤄짐
◇ 문제점
☞ convoy effect
☞ 소요시간이 긴 프로세스가 먼저 도달할 경우
☞ 순서 변경이 불가능해 효율성이 떨어지는 현상이 발생
SJF
(Shortest – Job – First)
◆ 특징
☞ 비선점형 스케줄링
☞ 다른 프로세스가 먼저 도착하더라도 CPU burst time이 짧은 프로세스 먼저 할당
◇ 문제점
☞ stravation
☞ 효율성 추구가 중요하긴 하지만 특정 프로세스가 지나치게 차별받는 상황이 발생
☞ 극단적으로 CPU 사용이 짧은 프로세스를 선호
☞ 사용시간이 긴 프로세스는 할당 받을 가능성이 없음
SRTF
(Shortest Remaining Time First)
◆ 특징
☞ 선점형 스케줄링
☞ 새로운 프로세스가 도착할 때마다 새로운 스케줄링
☞ burst time이 짧은 새 프로세스가 도착시 진행중인 CPU를 넘겨준다
◇ 문제점
☞ starvation
☞ 새로운 프로세스 도달마다 새로 스케줄링을 진행
☞ CPU burst time을 측정할 수 없다
(CPU 사용시간)
Priority Scheduling
◆ 특징
☞ 우선순위가 가장 높은 프로세스에 CPU 할당
☞ 숫자가 작을수록 우선순위가 높음
☞ 선점형 비선점형 둘 다 사용
☞ 선점형 : 더 높은 숭위의 프로세스 도착시 실행중인 프로세스를 멈추고 CPU 선점
☞ 비선점형 : 더 높은 우선순위의 프로세스 도착시 Ready Queue의 Head에 넣는다
◇ 문제점
☞ starvation
☞ 실행 준비는 되어있으나 CPU 사용을 못해 무기한 대기하는 사태가 발생
(무기한 봉쇄 Idenfinite blocking)

해결책
 - 우선순위가 낮은 프로세스라도 오래 기다릴 경우 높은 우선순위 할당
Round Robin
◆ 특징
☞ 가장 현대적인 CPU 스케줄링
☞ 각 프로세스는 동일한 크기의 할당 시간을 가짐 (Time quantum)
☞ 할당 시간이 지나면 프로세스는 선점당하고 ready queue의 제일 뒤에 다시 배정
☞ CPU 사용시간이 랜덤한 프로세스들이 있을 경우에 효율적이다
☞ 프로세스의 문맥을 저장할 수 있다
◇ 문제점
장점
 - 응답시간이 빨라진다
 - 프로세스가 기다리는 시간이 CPU를 사용할 만큼 증가
 - 공정한 스케줄링

할당시간이 너무 길어질 경우 FCFS와 같아질 수 있고
할당시간이 너무 짧을 경우 문맥 교환으로 인한 overhead가 발생하기 때문에 적당한 time quantum 설정이 중요하다


convoy 현상
 - burst time이 긴 프로세스가 먼저 도착해 다른 프로세스의 실행 시간이 전부 늦춰져 효율이 떨어지는 현상

starvation
 - 계속해서 우선순위가 높은 프로세스가 먼저 실행되어 우선순위가 낮은 프로세스가 CPU 할당을 받지 못하는 현상

aging 기법
 - 먼저 도착한 프로세스 나이를 올려줘 우선순위를 올리는 기법

다단계 큐 (Multilevel Queue)
 - 선점 방식
 - Background에서 돌아가는 프로세스와 Foreground의 프로세으에 다른 알고리즘을 적용하는 방식
 - 큐 사이에 서로 다른 CPU 할당시간을 적용
 - Background 프로세스에는 FCFS /  Foreground 프로세스에는 Round Robin 적용

다단계 피드백 큐 (Multilevel Feedback Queue)
 - 프로세스가 큐 사이를 이동 가능
 - 각 큐에 서로 다른 CPU 할당시간을 적용
 - 프로세스가 해당 시간 동안 작업을 처리하지 못했다면, 점점 긴 time quantum을 해주는 큐로 이동
 - 우선순위는 할당시간이 짧은 큐가 높다
 - starvation이 발생 가능하며 aging으로 해결 가능


## 선점과 비선점 스케줄링 알고리즘
1. 선점(Preemptive) : STR, Round Robin, Priority Scheduling, Multilevel Scheduling
장점 : 우선순위가 높은 프로세스에 빠른 응답시간 보장
단점 : 프로세스간 문맥교환이 자주 발생 / stravation 발생 가능

2. 비선점(Nonpreemptive) : FCFS, SJF
장점 : 모든 프로세스에 대한 공정한 처리 / 문맥교환으로 인한 오버헤드가 적음
단점 : burst time이 긴 프로세스에 의해 짧은 프로세스가 기다리는 현상 발생

### Dispatch Latency와 Context Switching
1. Dispatch Latency
 - 스케줄러가 선택한 프로세스를 CPU에 할당하는 요소를 Dispatcher라고 함
 - Dispatcher가 하나의 프로세스를 중단하고, 다른 프로세스를 실행하기까지 소요하는 시간
2. Context Switching
 - 인터럽트로 인해 다음 우선순위의 프로세스가 실행될 때, 기존의 상태를 저장하고, 다음 프로세스를 수행할 수 있도록 PCB로부터 상태를 레지스터에 적재하는 작업

## 동기와 비동기
1. 동기 (Synchronous 동시에 일어나는)
 - 요청과 결과가 한 자리에서 동시에 일어남
 - A노드 B노드 사이의 작업 처리 단위(transaction)를 동시에 맞춘다
 - 설계가 매우 간단하고 직관적
 - 결과가 주어질 때까지 다른 것을 하지 못하고 대기해야 하는 단점을 보유

2. 비동기 (Asynchronous 동시에 일어나지 않는)
 - 요청한 그 자리에서 결과가 주어지지 않음
 - 노드 사이의 작업 처리 단위를 동시에 맞추지 않아도 된다
 - 동기보다 복잡하다
 - 결과가 주어지는데 시간이 걸리더라도 다른 작업을 할 수 있음
 - 동기보다 자원을 효율적으로 사용할 수 있는 장점을 보유

동기와 비동기는 어떠한 작업이나 그 작업과 연관된 작업을 처리하고자 하는 시각의 차이이다
동기는 추구하는 같은 목적이 동시에 이뤄지며
비동기는 추구하는 목적이 다를 수 있으며, 동시에 이뤄지지 않는다

![image](https://user-images.githubusercontent.com/97201374/181485174-31224aad-cec5-4137-a48a-6b48cde8ae22.png)



1. 동기식 처리 모델 (Synchronous processing model)
 - task를 직렬적으로 수행한다
 - 태스크는 순차적으로 실행되며 어떤 작업이 수행 중일시 다음 태스크는 대기하게 된다
ex) 서버에서 데이터를 가져와 화면에 표시하는 작업 수행 시, 서버에 데이터를 요청하고 데이터가 응답될 때까지 이후 태스크들은 blocking 된다

![image](https://user-images.githubusercontent.com/97201374/181485196-80fd68ad-0f84-4272-b07e-7afa716236d8.png)



2. 비동기식 처리 모델 (Asynchronous processing model)
 - task를 병렬적으로 수행한다
 - 태스크가 종료되지 않은 상태이더라도 대기하지 않고 다음 태스크를 실행
ex) 서버에서 데이터를 가져와 화면에 표시하는 작업 수행 시, 서버로부터 데이터가 응답될 때까지 대기하지 않고, 즉시 다음 태스크 수행
 이후에 서버로부터 데이터가 응답되면 이벤트가 발생하고, 이벤트 핸들러가 데이터를 가지고 수행할 태스크를 계속 수행한다
 
 ![image](https://user-images.githubusercontent.com/97201374/181485216-e5f07708-0898-42c9-9155-5e4554a161a7.png)



 자바스크립트의 대부분은 DOM 이벤트와 Timer 함수 (setTimeout, setInterval), Ajx 요청은 비동기식 처리 모델로 동작한다





## Block & Non-Block
함수 호출에서의 이야기로 생각하면 편하다
1. Block
 - 호출된 함수가 자신이 할 일을 모두 마칠 때까지 제어권을 계속 가지고 호출한 함수에게 바로 return하지 않음
2. Non-Block
 - 호출된 함수가 자신의 할 일을 마치지 않더라도 제어권을 바로 return하여 호출한 함수가 다른 일을 진행할 수 있도록 함

![image](https://user-images.githubusercontent.com/97201374/181485251-06dfe8ae-6a8b-4b12-9d75-88b6710a7e46.png)


블로킹 & 논블로킹 – 동시성과 무관한 이야기
 - 메서드 호출 한 후로 시간이 오래 걸리면 블로킹
 - 메서드가 얼마나 오래 걸리느냐의 문제로 블로킹, 논블로킹을 구분
 - 기술적으로 명확히 구분 (함수 호출에 관한 이야기)
ex) A 함수를 호출했을 때, A 함수를 호출하며 기대하는 행위를 모두 끝마칠 때까지 기다렸다가 return시 블로킹
ex) A 함수를 호출했을 때, A 함수를 호출시 기대하는 행위를 요청하고 즉시 return되면 논블로킹


## 동기 & 비동기 / 블록 & 논블록 조합 정의
1. 블록 / 동기
 - A가 실행되다가 B라는 일을 수행하는 함수를 호출 → B 시작
 - B가 끝나면 함수를 return
 - A와 B는 순차적으로 진행되기에 동기
 - B라는 함수를 호출하고 그 일이 끝나고 나서 함수가 return 되므로 블록

2. 블록 / 비동기
 - A는 B라는 일을 시킨다
 - 일을 시킨 즉시 바로 리턴
 - B는 일을 시작하고, A도 자신의 일을 시작
 - A는 중간에 B에게 중간 보고를 받아 처리
 - A는 B에게 보고를 요청, 중간 보고를 기다린다 (block)
 - 요청의 결과를 받고 그 결과를 이용하여 A의 일을 처리
 - 동시에 B는 보고 후 자신의 일을 동시에 진행
 - (비동기) A는 다시 B에게 중간결과를 요청하며 기다린다 (block)
 - 요청의 결과를 받고 A는 자신의 일, B도 자신의 일을 함
 - 이러한 과정을 반복한다

3. 논블록 / 동기
 - A는 B라는 일을 시킨다.
 - 일을 시킨 즉시 바로 리턴
 - (논블록) B는 일을 시작하는데, A는 아직 자신의 일을 시작하지 않는다
 - A의 일이 B일이 진행되는 것을 확인하는 것이기 때문
 - B의 결과를 확인하는 함수를 호출하고 바로 return
 - 결과 보고를 받는 것이 아니라 결과 보고를 하라고 함수를 호출하는 것
 - 이러한 (결과 보고 요청)독촉을 계속 반복
 - 이후 B의 결과 보고가 진행되면 B는 일이 종료, A는 자신의 일을 처리 (순차적 진행)

4. 논블록 / 비동기
 - A는 B의 일을 시작시킨다
 - 일을 시킨 즉시 바로 리턴
 - A와 B는 각자 자신의 일을 처리한다 (병행처리)


## 동시성 문제
동시성 문제란 두 개 이상의 세션이 공통된 자원에 대해 모두 읽고 쓰는 작업(Read – Write)을 하려고 하는경우에 발생할 수 있는 문제를 말한다

 애플리케이션을 개발하다보면 여러 동시성 문제들을 만나고, 동시성 제어를 도와주는 여러 시스템을 만나게 된다 (데이터베이스, JPA 시스템)
 
 동시성 문제에 “완전한 해결”은 없으며, “제어(적절한 해결)”만이 있을 뿐입니다.
 “정확성과 활동성을 어떻게 하면 모두 최대로 할 수 있을까?”에 대한 고민이며, 활동성을 포기하면 정확성을 높일 수 있다, 반대의 경우도 마찬가지이다
동시성 문제 2가지 현상

1. 일관성 없는 읽기
 - “불변성” 복사본을 이용
 - 세션2가 최초로 데이터를 조회할 때, 해당 데이터를 복사한 후, 이후에도 계속 사용
 - 세션1이 변경한 데이터의 원장은 감지하지 못하더라도
 - 세션2 내에서는 계속 동일한 복사본을 바라볼 수 있음

![image](https://user-images.githubusercontent.com/97201374/181485285-add1eb5b-3848-4af7-9abd-91a16292e3ee.png)


2. 손실되는 업데이트
 - 늦게 시작한 세션2에 의해서 세션1의 변경사항이 무시되는 현상을 일컫는다
 
 ![image](https://user-images.githubusercontent.com/97201374/181485299-aeb5b0c9-fe0d-497f-9137-e75ca6c51ea5.png)


이러한 손실되는 업데이트를 방지하기 위한 두 가지 방법 “낙관적 잠금”, “비관적 잠금”

1) 낙관적 잠금

![image](https://user-images.githubusercontent.com/97201374/181485316-462535b1-ae9f-4d00-9d54-94576b76f52d.png)


 - 저장 시 체크하기
 - 세션1이 데이터 A를 읽어왔더라도 세션2는 자유롭게 데이터A를 읽을 수 있다
 - 다만, 저장 시 대상 데이터가 세션2가 들고온 데이터와 다를 경우 저장되지 않는다
 - 낙관적 잠금을 구현하기 위해서는 공통된 리소스A에 대한 Versionning이 되어야 한다
 
2) 비관적 잠금

![image](https://user-images.githubusercontent.com/97201374/181485325-7b453974-1699-4601-bebc-8b5e80e3121d.png)


 - 이미 읽어들이고 있는 사람이 있으면, 읽을 수 없음
 - 보수적 잠금이라고 생각할 수 있다
 - 낙관적 잠금에 비해 세션이 실패할 확률은 줄어들음
 - 여러 세션의 “활동성”을 높여줄 수 없다

### 동시성 문제 종류
1. Critical Section(임계영역)
 - 프로세스 간 공유 자원(Shared Resource) 접근에 있어 문제가 발생하지 않도록
 - 한 번에 하나의 프로세스만 이용하게 보장해줘야 하는 영역
 - 공유 자원의 독점을 보장하는 코드 영역을 의미하며, 지정된 시간이 지난 후 영역이 종료된다
 - 동일한 자원을 동시에 접근하는 작업 (공유 변수, 동일파일 사용 등)을  실행하는 코드 영역을 칭함
 - 임계영역 문제 해결을 위한 세 가지 조건

a. 상호 배제 (Mutual exclution)
 - 하나의 프로세스가 임계영역에 들어가 있다면 다른 프로세스는 들어갈 수 없어야 한다
 - SW로 가능하지만 매우 복잡하여 HW로 보조한다
b. 진행 (Progress) - No Deadlock
 - 임계영역에 들어간 프로세스가 없는 상태에서 들어가려는 프로세스가 여러 개일 경우 어떤 것이 들어갈지 결정해줘야 함 (진입 후보로서 참여가 가능)
 - 임계영역에 어떤 스레드의 접근이 없을 때, 항상 접근이 가능해야 함
 - 순서가 정해질 경우에 뒤로 밀려진 프로세스가 무한정 연기되어서는 안된다
c. 한정 대기 (Bounded waiting) - No starvation
 - 다른 프로세스의 starvation을 방지하기 위해, 한 번의 임계 구역에 들어간 프로세스는
 - 다음 임계영역에 들어갈 때 제한을 두어야 함 (진입 횟수의 제한)
 - 모든 프로세스가 임계영역에 들어갈 기회를 가져야 함

소프트웨어 측면에서의 고급 솔루션 방법
 - Mutex (Binary Semaphore) : 가장 간단한 동기화 툴 (locking)
 - Semaphore (Counting Semaphore) : 더욱 편리하고 효과적
 - Monitor : 뮤텍스와 세마포어의 단점을 극복 → Java에서 생각하는 모든 locking은 Monitor이다

Lock
 - 하드웨어 기반 해결책으로, 동시에 공유 자원 접근을 막기 위해 임계영역에 진입하는 프로세스는 Lock를 획득
 - 임계영역에서 빠져나올 때, Lock를 방출함으로 동시에 접근이 되지 않도록 한다

Semaphores
 - 신호기
 - SW 상에서 임계영역 문제를 해결하기 위한 동기화 도구
 
 ![image](https://user-images.githubusercontent.com/97201374/181485357-4bf3818a-7339-484a-b3bf-cdd1b88d7fe7.png)


 - 공유된 자원의 데이터를 여러 프로세스가 접근하는 것을 막는 것
 - 일반적으로 긴 시간을 확보하는 리소스에 대해 이용
 - 운영체제의 리소스를 경쟁적으로 사용하는 다중 프로세스에서 행동을 조정하거나 동기화 시키는 기술

Mutex
 - 상호 배제의 머릿글자를 따서 이름을 지음
 - 0, 1 사이의 값만 사용이 가능하며, 다중 프로세스 사이의 임계영역 문제를 해결하기 위함
 - Busy waiting 문제가 발생
 - 임계영역에 들어가기 위해 무한루프에 빠지는 것
 
 ![image](https://user-images.githubusercontent.com/97201374/181485380-723de5b0-9f71-46ed-9df9-dee810188ca1.png)


 - 공유된 자원의 데이터를 여러 스레드가 접근하는 것을 막음
 - 임계영역을 가진 스레드들의 running time이 서로 겹치지 않게 단독으로 실행되게 함
 - 다중 프로세스들을 상호 배제함으로 두 스레드가 동시에 사용할 수 없게 함

Spin Lock
 - busy wating을 하는 semaphore
 - 다른 스레드가 lock를 소유하고 있다면 lock가 반환될 때까지 계속 확인하며 기다리는 것
 - 임계영역으로 진입이 불가능할 때, 문맥 교환을 하지 않고 잠시 루프를 돌며 재시도 하는 것

2. Race Condition
 - 두 개의 프로세스가 공통 자원을 병행적으로 읽거나 쓰는 동작을 할 때, 공용 데이터에 대한 접근이 어떤 순서에 따라 이뤄졌는지 확인
 - 그 실행 결과가 같지 않고 달라지는 상황을 말한다
 - 경쟁 상태의 두 개의 스레드가 하나의 자원을 두고 서로 사용하려고 하는 상황
 - 이러한 경쟁 프로세스의 경우 세 가지 문제에 직면 (Mutual exclusion, Deadlock, Starvation)

 - Race condition 상황인 경우에 스레드 실행 순서를 조절해주지 않으면 비정상적인 상태가 발생
 - Race condition은 디버깅을 할 때, 전혀 보이지 않는 문제점이며, 발생 시 모든 프로세스에 원하는 결과 발생을 보장할 수 없으므로 반드시 피해야 하는 상황이다
 
 - Race Condition을 예방할 수 있는 방법으로 Semaphore와 Mutex가 있다

3. Deadlock (교착상태)
 - 두 개 이상의 프로세스나 스레드가 공유 자원을 얻어내지 못해 다음 처리를 진행하지 못하는 상황
 - 어떠한 작업도 수행하지 못하고 무한히 다음 자원을 기다리게 되는 상태
 - 시스템적으로 한정된 자원을 여러 곳에서 사용하려다 발생
 
 ![image](https://user-images.githubusercontent.com/97201374/181485403-a15bcfea-4c68-4d6d-a49b-bcf260231792.png)



프로세스1과 2가 모두 자원을 얻어야 하는 상태로 가정
하지만, 현재 서로 원하는 자원이 할당되어있어 원하는 자원을 기다리며 무한정 wait 상태에 빠짐

4. DeadLock 발생 조건 4가지 (모두 성립해야 발생)
a. 상호 배제 : 자원은 한 번에 한 프로세스만 사용할 수 있음
b. 점유 대기 : 최소한 하나의 자원을 점유하고 있으면서 다른 프로세스에 할당되어 사용하고 있는 자원을 얻어내기 위해 대기하는 프로세스가 존재
c. 비선점 : 다른 프로세스에 할당된 자원은 사용이 끝날 때까지 강제로 얻어낼 수 없음 (동기)
d. 순환 대기 : 프로세스의 집합에서 순환 형태로 자원을 대기하고 있어야 함

5. DeadLock 처리
a. 예방 (prevention)
☞ 교착 상태 발생 조건 중 하나를 제거하면서 해결 (자원 낭비가 심하다)
 - 상호배제 부정 : 여러 프로세스가 공유 자원을 할당
 - 점유 대기 부정 : 프로세스 실행 전 모든 자원을 할당
 - 비선점 부정 : 자원 점유 중인 프로세스가 다른 자원을 요구할 때 가진 자원 반납
 - 순환대기 부정 : 자원에 고유번호 할당 후 순서대로 자원 요구
b. 회피 (avoidance)
☞ 교착 상태 발생 시 피해나가는 방법
 - 은행원 알고리즘(Banker’s Algorithm)
 - 은행에서 모든 고객의 요구가 충족되도록 현금 할당하는 데에서 유래
 - 프로세스가 자원을 요구할 때, 시스템은 자원을 할당한 후에도 안정 상태로 남아있는지 사전 검사하여 교착 상태 회피
 - 안정 상태일 경우 자원 할당 & 불안정 상태일 경우 다른 프로세스드르이 자원 해지까지 대기

c. 탐지 (detection)
☞ 자원 할당 그래프를 통해 교착 상태를 탐지
☞ 자원 요청 시, 탐지 알고리즘을 실행시켜 그에 대한 오버헤드 발생
d. 회복 (recovery)
☞ 교착 상태를 일으킨 프로세스를 종료하거나, 할당된 자원을 해제시켜 회복시키는 방법

프로세스를 종료하는 방법
 - 교착 상태의 프로세스 모두 중지
 - 교착 상태가 제거될 때까지 하나씩 프로세스 중지

자원 선점 방법
 - 교착 상태의 프로세스가 점유하고 있는 자원을 선점해 다른 프로세스에 할당
(해당 프로세스 일시 정지)
 - 우선순위가 낮은 프로세스나 수행 횟수가 적은 프로세스 위주로 프로세스 자원 선점


## 메모리 관리 전략
1. 페이징 (Paging)
 - 프로세스를 일정 크기인 페이지로 잘라서 메모리를 적재하는 방식
 - 페이지와 프레임
	페이지 : 고정 사이즈의 가상 메모리 내 프로세스 조각
	프레임 : 페이지 크기와 같은 주 기억장치의 메모리 조각
 - 프로세스는 페이지로 나뉘어지고, 물리 메모리는 프레임으로 나눠진다
 - 하나의 프로세스가 사용하는 메모리 공간이 연속적이어야 한다는 제약을 없앰

![image](https://user-images.githubusercontent.com/97201374/181485436-d07c6d89-e936-4bc6-9ea5-97be52999d49.png)


 - 페이징 테이블의 매핑을 나타낸 사진
 - 물리 메모리는 고정 크기의 프레임 / 가상 메모리는 고정 크기의 페이지로 분리
 - 개별 페이지는 순서에 상관없이 물리 메모리에 있는 프레임에 매핑되어 저장
 - 페이지 테이블에는 각 페이지 번호와 해당 페이지가 할당된 프레임의 시작 물리 주소를 저장
 - 모든 프로세스는 하나의 페이징 테이블을 가지고 있다
 - 페이징 테이블에는 메인 메모리에 적재되어있는 페이지 번호와 해당 페이지가 위치한 메인 메모리의 시작주소가 있다
 - 이러한 주소를 통해서 하나의 프로세스를 나눈 가상 메모리 페이지들이 각각 실제 메인 메모리의 어떤 프레임에 적재되어있는지 알 수 있다
 - 가상 메모리 사용

☞ 논리 주소와 페이지 테이블
 - 메모리 관리 장치 (Memory Mangement Unit, MMU)는 가상 주소(논리 주소)를 이용해 실제 데이터가 담겨 있는 주소로 변환
 - 논리 주소는 <page, offset> 형태로 구성되는데, 이는 물리 주소로 변환해 주는 것

![image](https://user-images.githubusercontent.com/97201374/181485462-1cc63ff6-d518-4cf7-92de-61a08cb78b42.png)


☞ 페이징의 장단점
 - 장점 : 논리 메모리는 물리 메모리에 저장될 때 연속되어 저장될 필요가 없음
 	: 물리 메모리의 남는 프레임에 적절히 배치됨
	: 이에 외부 단편화가 발생하지 않는다
 - 단점 : 내부 단편화 문제가 발생할 수 있다
	: 페이지 단위를 작게하면 해결이 가능
	: but, 페이지 매핑 과정이 복잡해져 비효율적이다

![image](https://user-images.githubusercontent.com/97201374/181485487-6370ad7a-65c3-4776-a52a-0aa66b76293a.png)



2. 세그멘테이션 (Segmantation)
 - 가상 메모리를 서로 크기가 다른 논리적 단위로 분할한 것
 - 프로세스를 논리적 단위인 세그먼트로 분할해서 메모리에 적재하는 방식
 - 의미가 같지 않는 논리적 내용을 기준으로 프로그램을 분할
 - 크기가 일정하지 않다

![image](https://user-images.githubusercontent.com/97201374/181485504-5d44b00f-a819-4cdd-b10e-63c067f5c638.png)


 - 사용자 / 프로그래머 관점의 메모리 기법
 - Segment : 페이지와 비슷한 개념이지만, 프로세스를 논리적 내용을 기반으로 나눠 메모리에 배치
 - 프로세스를 Code, Data, Stack으로 나눔
 - 세그먼트 테이블은 세그먼트 번호와 시작 주소(base), 세그먼트 크기(limit)를 엔트리로 가짐
 - CPU에서 해당 세그먼트의 크기를 넘어서는 주소가 들어오면 인터럽트가 발생해 해당 프로세스를 강제 종료
 - 가상 메모리 사용

☞ 세그멘테이션의 장단점
 - 장점 : 내부 단편화 문제가 해소된다
 	: 보호와 공유 기능을 수행할 수 있다
	: 프로그램의 중요한 부분과 중요하지 않는 부분을 분리하여 저장
	: 같은 코드 영역은 한 번에 저장할 수 있다
- 단점 : 외부 단편화 문제가 발생할 수 있다
- 

MMU (주기억장치)
 - CPU가 직접 접근할 수 있는 기억 장치로, 프로세스가 실행되려면 프로그램 코드를 메인 메모리에 적재해야 한다

Virtual Memory (가상 메모리)
 - 실제 물리 메모리 개념 & 사용자 논리 메모리 개념을 분리
 - 메모리 공간은 한정적이므로 사용자에게 더 많은 메모리를 제공하기 위해 가상 주소 사용
 - 메모리 관리 장치는 가상 주소를 이용해 실제 데이터가 담겨 있는 주소로 변환
 - 가상 주소 공간은 하나의 프로세스가 메모리에 저장되는 논리적 모습을 가상 메모리에 구현한 공강
 - 가상 주소는 해당 공간을 가리키는 주소이다

Swapping
 - CPU 할당 시간이 끝난 프로세스의 메모리를 보조 기억 장치에 내보내고(swap-out)
 - 다른 프로세스의 메모리를 불러오는(swap-in) 작업
 - 이러한 Swap 작업에는 디스크 전송 시간이 들기 때문에 메모리 공간이 부족할 때 Swapping이 이뤄진다
메모리 관리
 - 다중 프로그래밍 시스템에 여러 프로세스를 수용하기 위해 주 기억장치 (RAM)을 동적 분할하는 메모리 관리 작업이 필요
 - 하드 디스크에 있는 프로그램을 어떻게 메인 메모리에 적재할 것인지 판단

연속 메모리 관리
 ☞ 고정 분할 기법 : 주 기억장치가 고정된 파티션으로 분할 → 내부 단편화 발생
 ☞ 동적 분할 기법 : 파티션들이 동적 생성되며 자신의 크기와 같은 파티션에 적재 → 외부 단편화 발생
 - 프로그램 전체가 하나의 커다란 공간에 연속적으로 할당되어야 한다

단편화 (Fragmentation)
 - 기억 장치의 빈 공간 또는 자료가 여러 조각으로 나뉘는 현상
 - 프로세스들이 메모리에 적재되고 제거되는 일이 반복
 - 프로세스들이 차지하는 메모리 틈 사이에 사용하지 못한 만큼의 자유공간이 늘어남
 - 실제로 사용가능한 메모리가 충분히 존재하지만 할당이 불가능한 상태
☞ 내부 단편화
 - 프로세스가 사용하는 메모리 공간에 남는 부분
 - 프로세스가 요청한 양보다 더 많은 메모리를 할당할 때 발생
 - 메모리 분할 자유 공간과 프로세스가 사용하는 공간 크기 차이를 의미
 - 메모리 할당할 때 프로세스가 필요한 양보다 더 큰 메모리가 할당되어 메모리 공간이 낭비되는 상황
☞ 외부 단편화
 - 메모리 공간 중 사용하지 못하게 되는 부분
 - 메모리 할당 및 해제 작업의 반복으로 작은 메모리가 중간중간 존재할 수 있다
 - 사용하지 않는 메모리가 존재해 총 메모리 공간은 충분하지만 할당할 수 없는 상황
 - 외부 단편화를 해결하기 위해 압축을 이용해 공간을 몰 수 있다
 - but, 작업 효율이 좋지 못하다
 - 메모리가 할당되고 해제되는 작업이 반복적으로 일어날 때 발생

불연속 메모리 관리
 - 프로그램 일부가 서로 다른 주소 공간에 할당될 수 있는 기법
 - 외부 단편화 해소를 위한 페이징과 내부 단편화 해소를 위한 세그멘테이션으로 구분
 - Page : 프로세스를 고정된 크기의 작은 블록들로 나눴을 때, 그 블록을 페이지라 함
 - Frame : 페이지 크기와 같은 주 기억장치 메모리 블록
 - Segment : 서로 다른 크기의 논리적 단위

＊ 페이징과 세그멘테이션

![image](https://user-images.githubusercontent.com/97201374/181485522-deb247d4-82c0-413f-9eac-c0c0d60d8d0e.png)


☞ 단순 페이지
 - 각 프로세스는 프레임과 같은 길이를 가진 균등 페이지로 나뉜다
 - 외부 단편화가 생기지 않는다
 - 내부 단편화가 존재할 수 있다
☞ 단순 세그멘테이션
 - 각 프로세스는 여러 세그먼트로 나뉜다
 - 메모리 효율을 개선한다
 - 동적 분할을 통한 오버헤드가 감소한다
 - 외부 단편화가 존재할 수 있다
 - 내부 단편화가 생기지 않는다
☞ 가상 메모리 세그멘테이션
 - 필요하지 않는 세그먼트들은 로드되지 않는다
 - 필요한 세그먼트가 있을 경우 나중에 자동으로 불러들인다
 - 복잡한 메모리 관리로 오버헤드가 발생할 수 있다
 - 내부 단편화가 생기지 않는다

☞ 둘의 차이점
 - paging은 고정 크기를 가짐
 - segmentation은 가변 크기를 가짐
 - paging은 내부 단편화 발생 가능 / segmantation은 외부 단편화 발생 가능

☞ 사용하는 이유
 - Memory Fragmentation을 해결하기 위한 방법
 - 다중 프로그래밍 시스템에서 여러 프로세스를 수용하기 위해 주 기억장치를 동적 분할하는 메모리 관리 기법이 필요하기 때문


### 메모리 (Memory)
 - 프로그램과 프로그램 수행에 필요한 데이터 및 코드를 저장하는 장치
 - 내부 기억장치인 주 기억장치
 - 외부 기억장치인 보조 기억장치
 - 메모리 접근은 순차적이고 지역화 되어있다

## 가상 메모리
 - 가상 메모리 기법은 애플리케이션을 실행하는데 얼마나 많은 메모리가 필요한지 집중 x
 - 애플리케이션을 실행하는데 최소한 얼마만큼의 메모리가 필요한지에 집중
 - 실제 메모리보다 공간이 많아 보이게 하는 기술
 - 프로세스가 실행될 때 메모리에 해당 프로세스 전체가 올라가지 않더라도 실행 가능하다는 점에 착안하여 고안

![image](https://user-images.githubusercontent.com/97201374/181485541-1bfca599-991b-40fa-ad8e-3070540b5d64.png)

 - 가상 메모리와 MMU의 관계

 - 가상 메모리 구현을 위해서는 MMU(Memory Management Unit)를 갖추고 있어야 함
 - MMU는 가상주소를 물리주소로 변환, 메모리를 보호하는 기능을 수행
 - MMU를 사용하게 되면, CPU가 각 메모리에 접근하기 전에 메모리 주소 번역 작업을 수행
 - MMU는 RAM을 여러 page로 나누어 각 페이지를 하나의 독립 항목으로 처리
 - 페이지 및 주소 번역 정보를 기억하는 작업이 가상 메모리 구현의 결정적 절차이다
 - 애플리케이션이 실행될 때, 일부분만 메모리에 올라가고
 - 나머지는 보조 기억장치에 위치 → 가상 메모리의 핵심은 보조 기억장치이다


여러 프로세스를 동시에 실행하는 시스템의 경우
☞ 메모리 용량 부족 이슈
☞ 프로세스 메모리 영역 간 침범 이슈
 두 가지 이유로 가상 메모리를 필요로 함


### 페이징 시스템과 MMU의 관계
☞ CPU 가상 주소 접근시
 - MMU 하드웨어 장치를 통해 물리 메모리 접근
☞ 프로세스 생성 시 물리 메모리에 페이지 테이블 정보가 생성
 - PCB 등에서 해당 페이지 테이블에 접근이 가능하고, 관련 정보는 물리 메모리에 적재한다
 - 프로세스 구동 시, 해당 페이지 테이블의 시작 주소가 별도의 레지스터(CR3)에 저장된다
 - CPU가 가상 주소에 접근 시, MMU가 CR3를 통해 페이지 테이블 시작 주소에 접근해 물리 주소를 가져온다

＊ 요구 페이징
 - 프로세스를 메인 메모리에 적재할 때 모든 메모리를 다 올리지 않음
 - 지금 당장 필요로 하는 코드 부분만 메모리에 올리는 방법을 채택
 - 프로세스들이 메모리상에 다 올라와 있는 것처럼 보이게 해 공간이 커보이게 한다
 
 - 프로세스 이미지를 backing store에 저장한다
 - backing store는 swap device로 하드웨어 부분이며, 페이지를 임시로 보관하는 공간
 - 프로세스는 페이지의 조합이기 때문에 필요한 페이지만 메모리에 올린다
 - 필요한 페이지만 올려 메모리 사용량이 감소 & 입출력 오버헤드 감소
 - 프로그램이 물리적 메모리 용량의 제약에서 벗어나 메모리보다 더 큰 프로그램도 실행
 
 ![image](https://user-images.githubusercontent.com/97201374/181485569-0d9bc511-747e-4981-a238-c19e23208757.png)

 
 - 페이징 기법을 사용할 때, 페이지 테이블 부분을 놔둔다
 - 요구 페이징 기법을 사용하면 페이지가 메모리에 올라와 있는 부분, backing store에 저장되어 있는 것 두 가지가 존재
 - 이 두 가지를 구분해줄 도구가 필요
 - valid 비트 필드를 페이지 테이블에 추가
 - 0, 1의 값으로 메모리에 적재되어있는지 없는지를 구분
 - 오류가 발생 시 오류 제어할 수 있는 코드를 실행해야 함
 - 오류가 발생 시 backing store에서 해당 페이지를 가져와 수행
 - 이를 수행하기 위해 CPU는 잠시 하던 일을 멈추고 운영체제가 직접 나서 bacing store를 탐색하여 필요한 페이지를 메모리에 적재
 
 - 이 기간동안 페이지가 결함, 부재이기 때문에 페이지 부재라고 부른다

## 페이지 부재 트랩 (Paging fault trap)
 - 페이지에 실제 물리 메모리가 없을 때 일어나는 인터럽트
 - page fault 인터럽트가 일어나면 해당 페이지를 물리 메모리에 올림

![image](https://user-images.githubusercontent.com/97201374/181485583-fe9418a6-6cff-439a-be68-ae8e0605e924.png)


 - 페이지 폴트가 자주 일어나면 프로세스 실행 시간이 길어지게 된다
 - 프로세스 전환 시 메모리에 올라가 있던 데이터를 또다시 저장 매체에 기록 (page swap)
 - 이러한 page swap도 프로그램 반응 속도 느려지는데 기여
 - 필요한 프로그램만 사용하거나 메모리를 늘리는 방법도 존재한다


## 페이지 부재 발생 순서
CPU가 무효 페이지에 접근, 주소 변환을 담당하는 하드웨어인 MMU가 페이지 부재 트랩을 발생시키게 된다
 - CPU의 제어권이 커널 모드(kernal mode)로 전환되고, 운영체제의 페이지 부재 처리 루틴(page fault handler)이 호출되어 다음과 같은 순서로 페이지 부재를 처리

1. 운영 체제는 해당 페이지에 대한 접근이 적법한지 체크
 - 사용되지 않는 주소 영역에 접근하거나 해당 페이지에 대한 접근 권한 위반일 경우 해당 프로세스를 종료

2. 접근이 적법한 경우 물리적 메모리에서 비어있는 프레임을 할당받아 그 공간의 페이지를 읽어온다
 - 비어있는 프레임이 없다면 페이지 교체 알고리즘을 통해 물리적 메모리에 있는 프레임 하나를 swap 영역으로 쫓아내 비어있는 프레임을 만들어 적재 (swap out)

3. 페이지 테이블에서 해당 페이지의 유효-무효 비트를 유효비트로 설정하고 프로세스를 ready-Queue로 이동
 - 다시 CPU를 할당받았을 때 PCB에 있던 값을 복원시켜 중단되었던 명령을 수행

＊ 페이지 교체 알고리즘
FIFO (First In First Out)
![image](https://user-images.githubusercontent.com/97201374/181485604-2278cdc6-7ffa-4ec6-8ae2-333b3dd4d4ac.png)

 - 가장 먼저 들어온 페이지를 내린다
 - 물리 메모리에 페이지를 추가할 공간이 부족
 - 제일 먼저 들어온 페이지의 위치에 새로운 페이지를 올려 교체한다
 - 간단하며, 초기화 코드에 대해 적절한 방법
 - 들어온 시간을 저장하거나 올라온 순서를 큐에 저장
 - 프레임 수가 많아질수록 페이지 결함의 횟수는 감소

OPT (최적 페이지 교체 알고리즘 OPTimal Replacement Algorithm)
![image](https://user-images.githubusercontent.com/97201374/181485628-cbd5b4ec-1187-4740-9939-b19842ead176.png)

 - 앞으로 가장 오랫동안 사용하지 않을 페이지를 내린다
 - 일반 OS에서는 구현이 불가
 - 가장 이상적이지만 앞으로 사용할 페이지를 미리 알아야하기 때문에 불가능하다

LRU (Least Recently Used)
![image](https://user-images.githubusercontent.com/97201374/181485637-c914d223-9de2-47a9-ab96-5a6cd55e5a07.png)

 - 가장 오래전에 사용된 페이지를 교체
 - OPT 교체 알고리즘은 구현이 불가능하므로, 대신 가장 사용한 지 오래된 페이지를 새로운 페이지와 교체하는 방식으로 구현
 - 페이지마다 카운터가 필요
 - 큐로 구현이 가능하며, 사용한 데이터를 큐에서 제거하여 맨 위로 다시 올리고, 프레임이 모자랄 경우 맨 아래 데이터를 삭제
 - 프로세스가 주 기억장치에 접근할 때마다 참조된 페이지 시간을 기록해야 하므로 엄청난 오버헤드가 발생
 - 카운터나 큐, 스택과 같은 별도의 하드웨어가 필요
 - 가장 많이 사용되는 페이지 교체 알고리즘

LFU (Least Frequently Used)
 - 가장 적게 사용된 페이지를 새로운 페이지와 교체
 - LRU는 직전 참조된 시점만을 반영하지만, LFU는 참조 횟수를 통해 장기적 시간 규모에서의 참조만 고려할 수 있음
 - 가장 최근에 불러온 페이지가 교체될 수 있는 불상사가 발생할 수 있다

MFU (Most Frequently Used)
 - 참조 횟수가 가장 많은 페이지 교체
 - 가장 많이 사용된 페이지가 앞으로 사용되지 않은거라는 가정이 필요

NUR (Not Used Recently)
![image](https://user-images.githubusercontent.com/97201374/181485649-c8454352-e879-46ed-944b-60a928b13cd1.png)

 - LRU와 마찬가지로 최근에 사용하지 않은 페이지부터 교체하는 기법
 - 각 페이지마다 참조 비트(R), 수정 비트(M)을 둔다 (R, M)
 	(0, 0), (0, 1), (1, 0), (1, 1) 순으로 페이지 교체
 - 교체되는 페이지의 참조 시점이 가장 오래되었다는 것을 보장하지는 못함
 - 적은 오버헤드로 적절한 성능을 불러올 수 있다
 - 동일한 그룹 내에서 무작위 선택
 - 각 페이지마다 두 개의 비트 (참조 비트 Refernece Bit)와 (변형 비트 Modified Bit)가 사용됨

 - 참조 비트 : 페이지가 참조되지 않았을 때 “0”, 호출되었을 때 “1”
(모든 참조 비트는 주기적으로 0으로 변경된다)
 - 변형 비트 : 페이지 내용이 변경되지 않았을 때 “0”, 변경되었을 때 “1”
 - 우선순위 : 참조 비트 >> 변형 비트)
## 동시성과 병렬성의 차이
☞ 동시성 (Concurrency) 
 - 동시에 실행되는 것처럼 보이는 것
 - 싱글, 멀티 코어에서 멀티 스레드를 동작시키기 위한 방식
 - 여러 개의 스레드를 번갈아가며 실행되는 방식

☞ 병렬성 (Parallelism)
 - 물리적으로 동시에 정확히 실행되는 것
 - 멀티 코어에서 멀티 스레드를 동작시키는 방식
 - 데이터 병렬성과 작업 병렬성으로 구분

 - 데이터 병렬성 : 전체 데이터를 나누어 서브 데이터로 나눈 뒤, 서브 데이터들을 병렬 처리해서 작업을 빠르게 수행하는 방법
 - 작업 병렬성 : 서로 다른 작업을 병렬처리하는 것을 말함

☞ 동시성 프로그래밍과 병렬성 프로그래밍의 차이
동시성과 병렬성 모두 비동기 동작을 구현할 수 있지만 동작 원리가 다르다
 - 동시성 : 싱글 코어, 멀티 코어에서 모두 구현 가능
 - 병렬성 : 멀티 코어에서만 구현 가능

![image](https://user-images.githubusercontent.com/97201374/181485664-cfd57d8a-7123-4be8-8bb8-1680acd97443.png)


# 운영체제
운영체제는 컴퓨터 시스템의 자원들을 효율적으로 관리하며, 사용자가 컴퓨터를 편리하고, 효과적으로 사용할 수 있도록 환경을 제공하는 여러 프로그램의 모임이다.<br/>
운영체제는 컴퓨터 사용자와 컴퓨터 하드웨어 간의 인터페이스로서 동작하는 시스템 소프트웨어의 일종으로, 다른 응용프로그램이 유용한 작업을 할 수 있도록 환경을 제공해 준다.

## 프로세스(Process)
프로세스는 컴퓨터에서 실행 중인 프로그램을 의미하며 스케줄링의 대상이 되는 작업(task)과 거의 같은 의미로 쓰인다.
-	Task : 작업 단위의 실행 단위
#### 프로세스 상태
![image](https://user-images.githubusercontent.com/85390517/181689711-4aaf4c28-0ba9-4ab6-a660-6522b41d0045.png)
-	**new(생성)** : 프로세스가 생성된 상태이다. OS 커널에 존재하는 Ready Queue에 올라가면 ready상태가 된다.
-	**ready(준비)** : 프로세스가 CPU로부터 메모리 공간을 할당받길 기다리는 상태이다. 이때 프로세스 스케줄러에 의해 프로세스가 할당을 받게 되면 running 상태가 된다. 이것을 dispatch 라고 한다. 
-	**running(실행)** : 명령어들이 실행되는 상태이다. 이때 interrupt(간섭)이 발생하면 ready 상태로 변한다. 실행을 끝마치면 exit(종료)되고 terminated 상태로 변한다. I/O(입출력)이나 event가 발생하면 waiting 상태로 변한다.
-	**waiting(대기)** : 특정 event가 발생하길 기다리는 상태이다. 이때 I/O 나 특정 event가 완료되면 ready상태로 변한다.
-	**terminated(종료)** : 프로세스가 실행을 끝마친 상태이다.
#### 프로세스 상태 전이
프로세스 상태 전이는 프로세스가 시스템내에 존재하는 동안 프로세스의 상태가 변하는 것을 의미하며, 프로세스의 상태를 아래와 같이 상태 전이도로 표시할 수 있다.

+ **디스패치(Dispatch)**
준비 리스트의 맨 앞에 있던 프로세스가 CPU를 점유하게 되는 것. 즉, 준비 상태에서 실행 상태로 바뀌게 되는 것.
  + **dispatch(processname) : ready -> running**
+ **보류(Block)**
 실행 상태의 프로세스가 허가된 시간을 다 쓰기 전에 입출력 동작이 필요한 경우, CPU를 자진 납세하고, 보류 상태로 넘어가는 것.
  + **block(processname) : runnning -> blocked**
+ **깨움(Wakeup)**
 입출력 작업 종료 등 기다리던 사건이 일어났을 때, 보류 상태에서 준비 상태로 넘어가는 과정
  + **wakeup (processname): blocked -> ready**
+ **시간제한(Timeout)**
 운영체제는 프로세스가 프로세서를 계속 독점해서 사용하지 못하게 하기 위해 clock interrupt 를 두어 프로세스가 일정시간 동안만 (시분할 시스템의 time slice) 프로세스를 점유할 수 있게 한다.
  + **timeout(processname): running -> ready**

### 프로세스 제어 블록(Process Control Block, PCB)
프로세스 제어 블록은 특정한 프로세스를 관리할 필요가 있는 정보를 포함하는 운영 체제 커널의 자료 구조이다. PCB는 운영체제가 프로세스를 표현한 것이라 할 수 있다.<br/>
운영체제가 프로세스 스케줄링을 위해 프로세스에 관한 모든 정보를 가지고 있는 데이터베이스를 PCB라고 한다.<br/>
운영체제에서 프로세스는 PCB로 나타내어지며, PCB는 프로세스에 대한 중요한 정보를 가지고 있는 자료이다. 각 프로세스가 생성될 때마다 고유의 PCB가 생성되고, 프로세스가 완료되면 PCB는 제거된다.<br/>
프로세스는 CPU를 점유하여 작업을 처리하다가도 상태가 전이되면, 진행하던 작업 내용들을 모두 정리하고 CPU를 반환해야 하는데, 이때 진행하던 작업들을 모두 저장하지 않으면 다음에 자신의 순서가 왔을 때 어떠한 작업을 해야하는지 알 수 없는 사태가 발생한다. <br/>
따라서 프로세스는 CPU가 처리하던 작업의 내용들을 자신의 PCB에 저장하고, 다음에 다시 CPU를 점유하여 작업을 수행해야 할 때 PCB로부터 해당 정보들을 CPU에 넘겨와서 계속해서 하던 작업을 진행할 수 있게 된다.<br/>
![image](https://user-images.githubusercontent.com/85390517/181691229-dedd33c5-53b5-45b2-a874-90dbb1b88712.png)<br/>

#### PCB 포함 정보
-	프로세스 식별자(Process ID): 프로세스 식별자는 운영체제에서 각 프로세스나 서비스를 식별하기 위해 할당하는 고유한 번호이다.
-	프로세스 상태(Process State): 생성, 준비, 실행, 대기, 완료 상태가 있다.
-	프로그램 계수기(Program Counter): 프로그램 계수기는 이 프로세스가 다음에 실행할 명령어의 주소를 가리킨다.
-	CPU 레지스터 및 일반 레지스터
-	CPU 스케줄링 정보: 우선 순위, 최종 실행 시각, CPU 점유시간 등
-	메모리 관리 정보: 해당 프로세스의 주소 공간 등
-	프로세스 계정 정보: 페이지 테이블, 스케줄링 큐 포인터, 소유자, 부모 등
-	입출력 상태 정보: 프로세스에 할당된 입출력장치 목록, 열린 파일 목록 등

#### PCB의 위치
PCB가 프로세스의 중요한 정보를 포함하고 있기 때문에, 일반 사용자가 접근하지 못하도록 메모리 영역 안에 남는다.<br/>
일부 운영 체제에서 PCB는 커널 스택의 처음에 위치한다.

## 스레드(Thread)
스레드는 프로세스 내에서 실행되는 작업의 흐름을 의미한다.<br/>
모든 프로세스에는 한 개 이상의 스레드가 존재하여 작업을 수행하고, 두 개 이상의 스레드를 가지는 프로세스를 멀티 스레드 프로세스라고 한다.

#### 스레드의 종류
+ 사용자 수준 스레드
  + 사용자 수준 스레드는 커널 영역의 상위에서 지원되며 일반적으로 사용자 수준의 라이브러리를 통해 구현된다.
  + 커널은 스레드의 존재를 인식하지 못하기 때문에 커널의 개입을 받지 않는다.
  + 커널에서 스레드가 하나라고 판단하기 때문에 하나의 스레드가 중단되면 나머지 모든 스레드 역시 중단된다.
  + 사용자 영역에서 생성 및 관리되므로 속도가 빠르다.
  + 커널의 개입을 받지 않기 때문에 이식성이 높다. (모든 운영체제에서 실행 가능)

+ 커널 수준 스레드
  + 커널 수준 스레드는 운영체제가 지원하는 스레드 기능으로 구현되며, 커널이 스레드의 생성 및 스케줄링 등을 관리한다.
  + 커널이 각 스레드를 개별적으로 관리하기 때문에 프로세스 내 스레드들이 병행으로 수행이 가능하다. 때문에 하나의 스레드가 중단되어도 다른 스레드는 계속 수행이 가능하다.
  + 생성 및 관리 속도가 느리다.

#### 프로세스와 스레드의 차이
+ 프로세스
  + 프로세스는 코드, 데이터, 스택, 힙을 각각 생성한다.
+ 스레드
  + 스택을 제외한 코드, 데이터, 힙은 스레드끼리 공유한다.

### 스택을 스레드마다 독립적으로 할당하는 이유
 스택은 함수 내에서 선언하는 변수 등을 저장하기 위해 사용되는 메모리 공간이므로 스택 영역이 독립적으로 할당되는 것은 독립적인 함수 호출이 가능하다.<br/>
 이는 스레드의 정의에 따라 독립적인 실행 흐름을 가질 수 있다. 또한 스택은 LIFO 구조이기 때문에 공유하게 된다면 원활한 실행 흐름을 제어하기 어렵다.

### PC Register를 스레드마다 독립적으로 할당하는 이유
 스레드는 CPU를 할당 받았다가 스케줄러에 의해 다시 선점당한다. 그렇기 때문에 명령어가 연속적으로 수행되지 못하고 어느 부분까지 수행했는지 기억할 필요가 있다.

## 멀티 스레드
 한 프로세스가 여러 스레드로 동시에 여러 작업을 수행하는 것

### 멀티 스레딩의 장점
-	프로그램의 일부분이 중단되거나 긴 작업을 수행하더라도 프로그램의 수행이 계속 되어 사용자에 대한 응답성이 증가한다.
-	멀티 프로세스보다 적은 메모리 공간을 차지하고 캐시 메모리를 비울 필요가 없기 때문에 context switching이 빠르다.
-	스레드 간 통신에 별도의 자원을 이용하지 않고도, 전역변수 공간이나 힙 영역을 통해 데이터를 주고받을 수 있다.
-	스택을 제외한 모든 영역이 메모리를 공유하므로 통신 부담이 적다.

### 멀티 스레딩의 문제점
-	Context switching, 동기화 등의 이유 때문에 싱글 코어 멀티 스레딩은 스레드 생성 시간이 오히려 오버헤드로 작용해 단일 스레드보다 느리다.
-	공유하는 자원에 동시에 접근하는 경우, 프로세스와 달리 스레드는 데이터와 힙 영역을 공유하기 때문에 어떤 스레드가 다른 스레드에서 사용 중인 변수나 자료구조에 접근하여 엉뚱한 값을 읽어오거나 수정할 수 있다. 따라서 동기화가 필요하다.
-	운영체제의 지원이 필요하다.
-	프로그래밍 난이도가 높다. 또한, 스레드 수만큼 자원을 많이 사용한다.

### 멀티 스레드 vs 멀티 프로세스
+ 멀티 스레드
  + 하나의 스레드에 문제가 생기면 전체 프로세스에 영향을 끼칠 수 있다.
  + 멀티 프로세스보다 적은 메모리 공간 차지, context witching 시 비용이 덜 들어 응답시간이 그만큼 빠르다.
  + 프로세스의 스택을 제외한 다른 자원을 공유하는 만큼 이로 인한 동기화 문제라는 단점이 존재한다.
+ 멀티 프로세스
  + 하나의 프로세스가 죽더라도 다른 프로세스에 영향을 끼치지 않는다.
  + 멀티 스레드보다 많은 메모리 공간과 CPU 시간을 차지하고, context switching 시 여러 무거운 작업들을 동반하며 비용이 많이 소요되어 응답 속도가 느려지는 단점이 존재한다.
<br/>
  + 대상 시스템의 특징에 따라 적합한 동작 방식을 선택하고 적용해야 한다.

## 스케줄러
한정적인 메모리를 프로세스가 효율적으로 사용할 수 있도록 작업을 할당시켜주는 역할을 한다.<br/>
프로세스를 스케줄링 하기 위한 Queue에는 세 가지 종류가 존재한다.
-	Job Queue : 현재 시스템 내에 있는 모든 프로세스의 집합
-	Ready Queue : 현재 메모리 내에 있으면서 CPU를 잡아서 실행되기를 기다리는 프로세스의 집합
-	Device Queue : Device I/O 작업을 대기하고 있는 프로세스의 집합
<br/>
각각의 Queue에 프로세스들을 넣고 빼주는 스케줄러에도 크게 세 가지 종류가 존재한다.

### 장기스케줄러(Long-term scheduler or job scheduler)
-	메모리는 한정되어 있는데 많은 프로세스들이 한꺼번에 메모리에 올라올 경우, 대용량 메모리(일반적으로 디스크)에 임시로 저장된다. 이 pool에 있는 프로세스 중 어떤 프로세스를 ready queue로 보낼 지 결정하는 역할을 한다.
-	메모리와 디스크 사이의 스케줄링을 담당
-	프로세스에 memory 및 각종 리소스를 할당
-	Degree of Multiprogramming 제어
(메모리에 여러 프로그램이 올라가는 것) 몇 개의 프로그램이 올라갈 것인지를 제어
-	프로세스의 상태 : new - ready

### 단기스케줄러(Short-term scheduler or CPU scheduler)
-	CPU와 메모리 사이의 스케줄링을 담당
-	Ready Queue에 존재하는 프로세스 중 어떤 프로세스를 running 시킬지 결정
-	프로세스레 CPU를 할당
-	프로세스의 상태 : ready - running - waiting - ready

### 중기스케줄러(Medium-term scheduler or Swapper)
-	여유 공간 마련을 위해 프로세스를 통째로 메모리에서 디스크로 쫓아냄
-	프로세스에게서 memory를 deallocate
-	현 시스템에서 메모리에 너무 많은 프로그램이 올라가는 것을 조절하는 스케줄러
-	프로세스의 상태 : ready - suspended

## CPU 스케줄러
메모리에 올라온 프로세스들 중 어떤 프로세스를 먼저 처리할지 순서를 정하는 것이다.<br/>
Ready Queue에 있는 프로세스들 중에 누구에게 CPU를 할당해 줄 것인지 정한다.

#### 비선점 스케줄링
-	어떤 프로세스가 CPU를 점유하고 있다면 해당 프로세스의 작업이 완료될 때까지 다른 프로세스가 강제로 CPU를 빼앗아 사용할 수 없는 스케줄링 기법이다.
-	종류 : FCFS, SJF, 우선순위, HRN, 기한부 알고리즘

#### 선점 스케줄링
-	하나의 프로세스가 CPU를 점유하고 있을 때, 우선순위가 높은 다른 프로세스가 CPU를 강제로 빼앗아 사용할 수 있는 스케줄링 기법이다.
-	종류 : Round Robin, SRT, 선점 우선순위, 다단계 큐, 다단계 피드백 큐 알고리즘

### FCFS(First Come First Served)
-	비선점 스케줄링
-	먼저 요청한 프로세스를 먼저 처리하는 방식
-	모든 프로세스의 우선순위가 동일하고, 프로세스의 CPU 처리 시간을 따로 고려하지 않기 때문에 매우 단순하고 공평한 방법이다.
-	CPU 처리 시간이 길지만 덜 중요한 작업이, CPU 처리 시간이 짧고 더 중요한 작업을 기다리게 할 수도 있다. - 이를 콘보이 효과라고 한다.
-	콘보이 효과 : CPU를 매우 오래 사용하는 프로세스가 도착하게 되면, 다른 프로세스가 CPU를 사용하는 데 기다리는 대기 시간이 매우 커지는 현상

### SJF(Shortest - Job - First)
-	비선점 스케줄링
-	CPU 작업 시간이 가장 짧은 프로세스 순으로 스케줄링 (빨리 끝나는 것부터 처리)
-	늦게 도착하더라도 CPU 처리 시간이 앞에 대기중인 프로세스보다 짧으면 먼저 CPU를 할당받을 수 있다. - 콘보이 효과 완화
-	모든 방식을 통틀어 평균 대기 시간을 가장 짧게 만드는 방식으로 알려져 있다.
-	CPU 처리 시간이 긴 프로세스의 경우 처리 시간이 짧은 프로세스가 계속해서 들어오면 Ready Queue에서 무한정 CPU를 기다려야 하는 상황이 발생할 수 있다. - 이를 기아(starvation) 현상이라고 한다.
-	기아(starvation) 현상 : 자신보다 우선순위가 높은 프로세스 때문에 오랫동안 CPU 할당을 받지 못하고 무한정 기다리는 현상

### SRTF(Shortest Remaining Time First)
-	SJF 방식을 선점형 스케줄링 방식으로 변경한 기법
-	CPU를 점유중인 프로세스보다 남은 CPU 처리 시간이 짧은 프로세스가 Ready Queue에 들어올 경우 새로 들어온 프로세스가 CPU를 점유할 수 있다.
-	어떤 알고리즘보다 평균 대기 시간이 가장 짧은 알고리즘이지만, 기본적으로 선점형 방식이기 때문에 잦은 context switching이 일어나고 그에 따른 오버헤드가 커진다.
-	기아(starvation) 현상이 더 심각하게 발생할 수 있다.
-	CPU 처리 시간은 예측하기가 힘들기 때문에 실제로 사용되기 어렵다

### Priority Scheduling
-	우선순위가 높은 프로세스에게 먼저 CPU를 할당하는 방식
-	선점, 비선점 둘 다 가능

### Round Robin
-	선점 스케줄링
-	RR 스케줄링이라고도 한다.
-	시분할 시스템에서 사용
-	FCFS 스케줄링 방식에 선점 스케줄링 방식과 Time Quantum 개념을 추가한 방식이다.
-	프로세스에게 각각 동일한 CPU 할당 시간(타임 슬라이스, quantum)을 부여해서 그 시간 동안만 CPU를 이용하게 한다.
-	어떤 프로세스가 CPU를 사용한 시간이 Time Quantum만큼 지나면 이 프로세스로부터 CPU 자원을 회수하고, 이 프로세스를 Ready Queue의 가장 뒤로 보낸다.
-	모든 프로세스가 최초 응답 시간을 빠르게 보장받을 수 있다는 큰 장점이 있고 자연스럽게 콘보이 효과 역시 줄어든다.

## 동기와 비동기 및 Sync와 Async 차이 (블로킹과 논블로킹)
-	제어권 : 제어권은 자신(함수)의 코드를 실행할 권리 같은 것이다. 제어권을 가진 함수는 자신의 코드를 끝까지 실행한 후, 자신을 호출한 함수에게 돌려준다.
-	결과값을 기다린다는 것 : A 함수에서 B 함수를 호출했을 때, A 함수가 B 함수의 결과값을 기다리느냐의 여부를 의미한다.

#### 동기(Synchronous)
-	동시에 일어난다는 의미이다.
-	작업을 동시에 수행하거나, 동시에 끝나거나, 끝나는 동시에 시작
-	함수를 호출하는 곳에서 호출되는 함수가 결과를 반환할 때까지 기다린다.
-	작업 완료 여부를 계속해서 확인한다.

#### 비동기(Asynchronous)
-	동시에 일어나지 않음을 의미한다.
-	시작, 종료가 일치하지 않으며, 끝나는 동시에 시작을 하지 않음
-	함수를 호출하는 곳에서 결과를 기다리지 않고, 다른 함수(callback)에서 결과를 처리한다.
-	작업 완료 여부를 확인하지 않는다.

#### 블로킹(Blocking)
-	특정 작업이 실행 요청을 받아서 실행하는 동안 다른 작업은 진행하지 못하고 대기하는 방식을 의미한다.
-	제어권이 호출된 함수에게 넘어가서 호출된 함수 내에서 작업이 모두 끝난 후 값이 리턴되고, 호출한 함수에게 다시 제어권이 넘어온다.
-	작업이 완료된 후 새로운 작업을 수행할 수 있다.
-	작업이 순차적으로 이루어지므로 작업 흐름을 쉽게 이해할 수 있다는 장점이 있다.
-	블로킹이 이루어지는 동안 하드웨어 리소스를 효율적으로 이용하지 못한다는 단점이 있고, 특히 블로킹이 일어나는 작업이 오래 걸리는 작업인 경우 이러한 단점은 더욱 부각된다.

#### 논블로킹(Non-Blocking)
-	특정 작업이 이미 수행중이어도, 그것과 상관없이 바로 다른 작업을 수행시키는 방식을 의미한다.
-	제어권이 계속 호출한 함수에 있기 때문에 작업의 완료여부와 관계없이 새로운 작업을 수행할 수 있다.
-	작업 흐름이 복잡해져서 이해가 쉽지 않다는 단점이 있다.
-	리소스가 낭비되는 시간이 없으므로, 하드웨어 리소스를 효율적으로 이용할 수 있다.

## 동기와 비동기 및 Block non-Block
## 동시성 문제 
동시성 문제는, 두 개 이상의 세션이 공통된 자원에 대해 모두 읽고 쓰는 작업(Read - Write)을 할 때 발생하는 문제를 뜻한다.
### Critical Section(임계영역)
-	한 번에 하나의 프로세스만 액세스 할 수 있는 코드영역을 의미한다.
-	둘 이상의 프로세스가 동시에 접근할 수 없다.
-	만약 여러 프로세스가 동시에 임계영역에 접근하려고 한다면 Race Condition이 발생한다.

### RaceCondition
-	두 개 이상의 프로세스가 공유 자원을 병행적으로 읽거나 쓰는 상황을 말하며, 공유 자원 접근 순서에 따라 실행 결과가 달라지는 상황을 말한다.
### Deadlock(교착상태)
-	프로세스가 자원을 얻지 못해 다음 처리를 하지 못하는 상태이다.
-	둘 이상의 프로세스가 각자 공유 자원을 할당 받은 후 다음 처리를 위해 다른 공유 자원을 할당 받아야할 때, 각자 필요한 자원이 상대방에게 할당 되어있는 경우 프로세스들이 다음 처리를 위한 공유 자원을 획득하기 위해 서로 무한정 대기하는 상태이다.

### Deadlock 발생 조건 
-	상호배제 (Mutual Excusion) : 한 번에 하나만 해당 자원을 사용할 수 있다. 사용 중인 자원을 다른 프로세스가 사용하려면 요청한 자원이 해제될 때까지 기다려야 한다.
-	점유 대기 (Hold and Wait) : 자원을 최소한 하나만 보유하고, 다른 프로세스에 할당된 자원을 점유하기 위해 대기하는 프로세스가 존재해야 한다.
-	비선점 (Non Preemptive) : 이미 할당된 자원을 강제로 빼앗을 수 없다.
-	순환 대기 (Circular wait) : 대기 프로세스의 집합이 순환 형태로 자원을 대기하고 있어야 한다.

### Deadlock 해결 방법  
+ 교착 상태 예방
  + 교착 상태가 발생하기 전에 미리 조치를 취하는 방식으로, 교착 상태 발생 조건 중 하나를 제거함으로써 해결한다.
  + 자원의 상호배제 조건 방지 : 모든 자원을 공유 허용
  + 점유와 대기 조건 방지 : 모든 자원에 대해 선점 허용
  + 비선점 조건 방지 : 필요 자원을 한 번에 모두 할당하기
  + 순환 대기 조건 방지 : 자원에게 순서 부여를 통해 프로세스 순서의 증가 방향으로만 자원 요청

+ 교착 상태 회피
  + 프로세스가 자원을 요구할 때, 시스템은 자원을 할당한 후에도 안정 상태로 남아있는가를 확인하여 교착 상태를 회피하는 방법

+ 교착 상태 탐지
  + Deadlock이 발생하면 빠르게 발견하고 문제를 해결하는 것

+ 교착 상태 회복
  + 교착 상태를 일으킨 프로세스를 종료하거나 할당된 자원을 해제하면서 회복

## 메모리 관리 전략
-	메모리 용량이 증가함에 따라 프로그램의 크기 또한 계속 증가하고 있기 때문에 메모리는 언제나 부족하다.
-	메모리 관리 전략은 제한된 물리 메모리의 효율적인 사용과 메모리 참조 방식을 제공하기 위한 전략이다.

### Paging(페이징)
-	메모리 공간이 연속적으로 할당되어야 한다는 제약조건을 없애는 메모리 관리 전략
-	논리 메모리는 고정 크기의 페이지, 물리 메모리는 고정 크기의 프레임 블록으로 나누어 관리
-	프로세스가 사용하는 공간을 논리 메모리에서 여러 개의 페이지로 나누어 관리하고, 개별 페이지는 순서에 상관없이 물리 메모리에 있는 프레임에 매핑되어 저장
-	MMU(Memory Management Unit)의 재배치 레지스터 방식을 활용해 CPU가 마치 프로세스가 연속된 메모리에 할당된 것처럼 인식하도록 함
-	Page에 여유 공간이 남게 되는 경우가 많기 때문에 내부 단편화가 발생하는 단점

### Segmentation(세그멘테이션)
-	페이징 기법과 반대로 논리 메모리와 물리 메모리를 같은 크기의 블록이 아닌, 서로 다른 크기의 논리적 단위인 세그먼트로 분할
-	서로 다른 크기의 세그먼트들이 적재되고 제거되다보면 빈 공간이 많은 수의 작은 조각으로 나뉘어 사용하지 못하기 때문에 외부 단편화 문제를 해결하지 못하는 단점

#### 세그멘테이션 페이징 혼용 기법
-	페이징과 세그메테이션을 혼용해 단편화를 최대한 줄이려는 전략
-	프로세스를 세그먼트(논리적 기능 단위)로 나눈 다음 세그먼트를 다시 페이지 단위로 나누어 관리
-	매핑 테이블을 두 번 거쳐야 하므로 속도가 느려짐

## 가상 메모리
-	물리 메모리 크기의 한계를 극복하기 위해 나온 기술
-	어떤 프로세스가 실행될 때 메모리에 해당 프로세스 전체가 올라가지 않더라도 실행이 가능하다는 점에 착안하여 고안되었음
-	가상 메모리의 핵심은 필요한 부분만 메모리에 적재(부분적재)하는 것 - 프로세스를 실행할 때, 실행에 필요한 부분만 메모리에 올린다.

### 가상 주소 공간
-	가상 주소 공간은 각 프로세스당 주어지는 논리적인 공간이다.
-	가상 주소 공간의 크기는 물리 메모리(RAM)의 크기와는 독립적이며, 레지스터 크기에 종속적이다.

### 프로세스간의 페이지 공유
-	시스템 라이브러리가 여러 프로세스들 사이에 공유될 수 있도록 한다. 각 프로세스들은 공유 라이브러리를 자신의 가상 주소 공간에 두고 사용하는 것처럼 인식하지만, 라이브러리가 올라가 있는 물리 메모리 페이지들은 모든 프로세스에 공유되고 있다.
-	프로세스들이 메모리를 공유하는 것을 가능하게 하고, 프로세스들은 공유 메모리를 통해 회신할 수 있다. 이 또한, 각 프로세스들은 각자 자신의 주소 공간처럼 인식하지만, 실제 물리 메모리는 공유되고 있다.
-	logical address는 physical address로부터 분리된다.
-	fork()를 통한 생성 과정에서 페이지들이 공유되는 것을 가능하게 한다.

### Demand Paging(요구 페이징)
-	프로그램 실행 시작 시에 프로그램 전체를 디스크에서 물리 메모리에 적재하는 대신, 초기에 필요한 것들만 적재하는 전략
-	CPU가 해당 페이지를 요구할 때까지 그 페이지를 메모리에 올리지 않는다.
-	한 번도 접근되지 않는 페이지는 물리 메모리에 전혀 적재되지 않는다.
-	페이지 부재(page fault)가 발생하면 그 때 트랩을 걸어 해당 페이지를 적재한다.

### Page fault trap(페이지 부재 트랩)
-	요구 페이징에서는 프로그램에 대한 모든 내용이 물리 메모리에 올라오지 않기 때문에 메모리에 없는 페이지에 접근하려 할 때 페이지 부재 트랩이 발생한다.
-	페이지 부재 트랩이 발생하면 원하는 페이지를 저장 장치에서 가져오게 되고, 만약 물리 메모리가 가득 차 있는 상태라면 페이지 교체가 이루어진다.
+ 페이지 부재 트랩 처리 과정
1.	페이지 부재 트랩 발생
2.	디스크에서 해당 페이지를 찾음
3.	빈 페이지 프레임을 찾음
4.	페이지 교체 알고리즘을 통해 Victim 페이지 선택
5.	Victim 페이지를 디스크에 저장
6.	비워진 페이지 프레임에 새 페이지를 읽어옴
7.	재시작

## 페이지 교체
페이징 기법으로 메모리를 관리하는 운영체제에서 필요한 페이지가 주기억장치에 적재되지 않았을 시(페이지 부재) 어떤 페이지 프레임을 선택하여 교체할 것인지 결정하는 방법
-	프레임 : 물리 메모리를 일정한 크기로 나눈 블록
-	페이지 : 가상 메모리를 일정한 크기로 나눈 블록

### FIFO 페이지 교체
-	FIFO, First In First Out
-	선입 선출
-	물리 메모리에 올라온 페이지 순으로 페이지 교체시점에 나가게 됨
-	큐를 이용해 쉽게 구현이 가능
-	오히려 페이지 부재율을 높일 수 있으며, Belady의 모순이 발생 가능
-	Belady의 모순 : 페이지 프레임의 개수를 늘려도 페이지 부재가 줄어들지 않는 모순 현상

### 최적 페이지 교체(Optimal Page Replacement)
-	OPT, Optimal Page Replacement
-	가장 오랫동안 사용되지 않을 페이지를 찾아 교체하는 것
-	낮은 페이지 부재율을 보장하지만, 구현이 어려움

### LRU 페이지 교체(LRU Page Replacement)
-	Least – Recently – Used Page Replacement
-	최적 페이지 교체에 근사한 알고리즘
-	가장 오랫동안 사용되지 않은 페이지를 선택해 교체
-	FIFO보다 낮은 페이지 부재율을 보장
-	우선순위 큐, Double Linked Queue & HashTable로 구현 가능

### LFU 페이지 교체(LFU Page Replacement)
-	Least – Frequently – Used Page Replacement
-	참조 횟수가 가장 작은 페이지를 교체
-	참조 횟수가 높을수록 앞으로 계속 참조할 것이라는 가정에 기인
-	어떤 프로세스가 특정 페이지를 집중적으로 사용하다가 다른 페이지를 집중적으로 사용하게 되면 초기 가정을 만족하지 못함

### MFU 페이지 교체(MFU Page Replacement)
-	Most – Frequently – Used Page Replacement
-	참조 횟수가 가장 많은 페이지를 교체
-	참조 횟수가 낮을수록 최근에 페이지 프레임에 올라왔고, 앞으로 사용될 가능성이 많다는 가정에 기인

## 기타 
### 동시성과 병령성 차이
+ 동시성 프로그래밍
  + 동시에 실행되는 것처럼 보이는 것
  + 싱글 코어(멀티 코어에서도 가능)에서 멀티 스레드를 동작 시키기 위한 방식
  + 여러 개의 스레드를 번갈아 가면서 실행되는 방식

+ 병렬성 프로그래밍
  + 물리적으로 동시에 정확히 실행되는 것
  + 멀티 코어에서 멀티 스레드를 동작시키기 위한 방식
  + 데이터 병렬성과 작업 병렬성으로 구분된다.
  + 데이터 병렬성 : 전체 데이터를 나누어 서브 데이터로 나눈 뒤, 서브 데이터들을 병렬 처리해서 작업을 빠르게 수행하는 방법
  + 작업 병렬성 : 서로 다른 작업을 병렬 처리하는 것을 말함

### 은행원 알고리즘 
-	교착상태 회피 알고리즘
-	교착상태에 빠질 가능성이 있는지, 없는지를 판단하기 위해 상태를 ‘안전 상태’와 ‘불안전 상태’로 나눈다. 그리고 운영체제는 안전 상태를 유지할 수 있는 요구만 수락해주고, 나머지 요구들은 안전 상태를 만족할 때까지 계속 거절한다.
-	안전 상태(Safe State) : 시스템이 교착 상태를 일으키지 않으면서 각 프로세스가 요구한 최대 요구량만큼 필요한 자원을 할당해줄 수 있는 상태. 안전순서열이 존재해야 한다.
-	불안전 상태(Unsafe State) : 안전순서열이 존재하지 않는 상태. 불안전 상태는 교착상태이기 위한 필요조건. 불안전 상태라 해서 무조건 교착상태가 발생하는 것이 아니라, 교착상태는 불안전 상태에서만 발생한다는 것이다.
-	은행원 알고리즘의 이름은 은행이 최소한 한 명에게 대출해줄 수 있는 금액을 항상 보유하고 있어야 한다는 개념에서 나온 것이다.<br/>

+ 은행원 알고리즘이 제대로 수행되기 위해 필요한 3가지
1.	MAX : 각 고객들이 얼마나 최대로 돈을 요구할지 = 각 프로세스가 자원을 최대로 얼마까지 요청할 수 있는지
2.	Allocated : 각 고객들이 현재 빌린 돈이 얼마인지 = 각 프로세스가 현재 보유하고 있는 자원이 얼마인지
3.	Available : 은행이 보유하고, 빌려줄 수 있는 돈은 얼마인지 = 시스템이 자원을 얼마나 보유하고 있는지
