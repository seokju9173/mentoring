# 운영체제
운영체제는 컴퓨터 시스템의 자원들을 효율적으로 관리하며, 사용자가 컴퓨터를 편리하고, 효과적으로 사용할 수 있도록 환경을 제공하는 여러 프로그램의 모임이다.<br/>
운영체제는 컴퓨터 사용자와 컴퓨터 하드웨어 간의 인터페이스로서 동작하는 시스템 소프트웨어의 일종으로, 다른 응용프로그램이 유용한 작업을 할 수 있도록 환경을 제공해 준다.

## 프로세스(Process)
프로세스는 컴퓨터에서 실행 중인 프로그램을 의미하며 스케줄링의 대상이 되는 작업(task)과 거의 같은 의미로 쓰인다.
-	Task : 작업 단위의 실행 단위
#### 프로세스 상태
![image](https://user-images.githubusercontent.com/85390517/181689711-4aaf4c28-0ba9-4ab6-a660-6522b41d0045.png)
-	**new(생성)** : 프로세스가 생성된 상태이다. OS 커널에 존재하는 Ready Queue에 올라가면 ready상태가 된다.
-	**ready(준비)** : 프로세스가 CPU로부터 메모리 공간을 할당받길 기다리는 상태이다. 이때 프로세스 스케줄러에 의해 프로세스가 할당을 받게 되면 running 상태가 된다. 이것을 dispatch 라고 한다. 
-	**running(실행)** : 명령어들이 실행되는 상태이다. 이때 interrupt(간섭)이 발생하면 ready 상태로 변한다. 실행을 끝마치면 exit(종료)되고 terminated 상태로 변한다. I/O(입출력)이나 event가 발생하면 waiting 상태로 변한다.
-	**waiting(대기)** : 특정 event가 발생하길 기다리는 상태이다. 이때 I/O 나 특정 event가 완료되면 ready상태로 변한다.
-	**terminated(종료)** : 프로세스가 실행을 끝마친 상태이다.
#### 프로세스 상태 전이
프로세스 상태 전이는 프로세스가 시스템내에 존재하는 동안 프로세스의 상태가 변하는 것을 의미하며, 프로세스의 상태를 아래와 같이 상태 전이도로 표시할 수 있다.

+ **디스패치(Dispatch)**
준비 리스트의 맨 앞에 있던 프로세스가 CPU를 점유하게 되는 것. 즉, 준비 상태에서 실행 상태로 바뀌게 되는 것.
  + **dispatch(processname) : ready -> running**
+ **보류(Block)**
 실행 상태의 프로세스가 허가된 시간을 다 쓰기 전에 입출력 동작이 필요한 경우, CPU를 자진 납세하고, 보류 상태로 넘어가는 것.
  + **block(processname) : runnning -> blocked**
+ **깨움(Wakeup)**
 입출력 작업 종료 등 기다리던 사건이 일어났을 때, 보류 상태에서 준비 상태로 넘어가는 과정
  + **wakeup (processname): blocked -> ready**
+ **시간제한(Timeout)**
 운영체제는 프로세스가 프로세서를 계속 독점해서 사용하지 못하게 하기 위해 clock interrupt 를 두어 프로세스가 일정시간 동안만 (시분할 시스템의 time slice) 프로세스를 점유할 수 있게 한다.
  + **timeout(processname): running -> ready**

### 프로세스 제어 블록(Process Control Block, PCB)
프로세스 제어 블록은 특정한 프로세스를 관리할 필요가 있는 정보를 포함하는 운영 체제 커널의 자료 구조이다. PCB는 운영체제가 프로세스를 표현한 것이라 할 수 있다.<br/>
운영체제가 프로세스 스케줄링을 위해 프로세스에 관한 모든 정보를 가지고 있는 데이터베이스를 PCB라고 한다.<br/>
운영체제에서 프로세스는 PCB로 나타내어지며, PCB는 프로세스에 대한 중요한 정보를 가지고 있는 자료이다. 각 프로세스가 생성될 때마다 고유의 PCB가 생성되고, 프로세스가 완료되면 PCB는 제거된다.<br/>
프로세스는 CPU를 점유하여 작업을 처리하다가도 상태가 전이되면, 진행하던 작업 내용들을 모두 정리하고 CPU를 반환해야 하는데, 이때 진행하던 작업들을 모두 저장하지 않으면 다음에 자신의 순서가 왔을 때 어떠한 작업을 해야하는지 알 수 없는 사태가 발생한다. <br/>
따라서 프로세스는 CPU가 처리하던 작업의 내용들을 자신의 PCB에 저장하고, 다음에 다시 CPU를 점유하여 작업을 수행해야 할 때 PCB로부터 해당 정보들을 CPU에 넘겨와서 계속해서 하던 작업을 진행할 수 있게 된다.<br/>
![image](https://user-images.githubusercontent.com/85390517/181691229-dedd33c5-53b5-45b2-a874-90dbb1b88712.png)<br/>

#### PCB 포함 정보
-	프로세스 식별자(Process ID): 프로세스 식별자는 운영체제에서 각 프로세스나 서비스를 식별하기 위해 할당하는 고유한 번호이다.
-	프로세스 상태(Process State): 생성, 준비, 실행, 대기, 완료 상태가 있다.
-	프로그램 계수기(Program Counter): 프로그램 계수기는 이 프로세스가 다음에 실행할 명령어의 주소를 가리킨다.
-	CPU 레지스터 및 일반 레지스터
-	CPU 스케줄링 정보: 우선 순위, 최종 실행 시각, CPU 점유시간 등
-	메모리 관리 정보: 해당 프로세스의 주소 공간 등
-	프로세스 계정 정보: 페이지 테이블, 스케줄링 큐 포인터, 소유자, 부모 등
-	입출력 상태 정보: 프로세스에 할당된 입출력장치 목록, 열린 파일 목록 등

#### PCB의 위치
PCB가 프로세스의 중요한 정보를 포함하고 있기 때문에, 일반 사용자가 접근하지 못하도록 메모리 영역 안에 남는다.<br/>
일부 운영 체제에서 PCB는 커널 스택의 처음에 위치한다.

## 스레드(Thread)
스레드는 프로세스 내에서 실행되는 작업의 흐름을 의미한다.<br/>
모든 프로세스에는 한 개 이상의 스레드가 존재하여 작업을 수행하고, 두 개 이상의 스레드를 가지는 프로세스를 멀티 스레드 프로세스라고 한다.

#### 스레드의 종류
+ 사용자 수준 스레드
  + 사용자 수준 스레드는 커널 영역의 상위에서 지원되며 일반적으로 사용자 수준의 라이브러리를 통해 구현된다.
  + 커널은 스레드의 존재를 인식하지 못하기 때문에 커널의 개입을 받지 않는다.
  + 커널에서 스레드가 하나라고 판단하기 때문에 하나의 스레드가 중단되면 나머지 모든 스레드 역시 중단된다.
  + 사용자 영역에서 생성 및 관리되므로 속도가 빠르다.
  + 커널의 개입을 받지 않기 때문에 이식성이 높다. (모든 운영체제에서 실행 가능)

+ 커널 수준 스레드
  + 커널 수준 스레드는 운영체제가 지원하는 스레드 기능으로 구현되며, 커널이 스레드의 생성 및 스케줄링 등을 관리한다.
  + 커널이 각 스레드를 개별적으로 관리하기 때문에 프로세스 내 스레드들이 병행으로 수행이 가능하다. 때문에 하나의 스레드가 중단되어도 다른 스레드는 계속 수행이 가능하다.
  + 생성 및 관리 속도가 느리다.

#### 프로세스와 스레드의 차이
+ 프로세스
  + 프로세스는 코드, 데이터, 스택, 힙을 각각 생성한다.
+ 스레드
  + 스택을 제외한 코드, 데이터, 힙은 스레드끼리 공유한다.

### 스택을 스레드마다 독립적으로 할당하는 이유
 스택은 함수 내에서 선언하는 변수 등을 저장하기 위해 사용되는 메모리 공간이므로 스택 영역이 독립적으로 할당되는 것은 독립적인 함수 호출이 가능하다.<br/>
 이는 스레드의 정의에 따라 독립적인 실행 흐름을 가질 수 있다. 또한 스택은 LIFO 구조이기 때문에 공유하게 된다면 원활한 실행 흐름을 제어하기 어렵다.

### PC Register를 스레드마다 독립적으로 할당하는 이유
 스레드는 CPU를 할당 받았다가 스케줄러에 의해 다시 선점당한다. 그렇기 때문에 명령어가 연속적으로 수행되지 못하고 어느 부분까지 수행했는지 기억할 필요가 있다.

## 멀티 스레드
 한 프로세스가 여러 스레드로 동시에 여러 작업을 수행하는 것

### 멀티 스레딩의 장점
-	프로그램의 일부분이 중단되거나 긴 작업을 수행하더라도 프로그램의 수행이 계속 되어 사용자에 대한 응답성이 증가한다.
-	멀티 프로세스보다 적은 메모리 공간을 차지하고 캐시 메모리를 비울 필요가 없기 때문에 context switching이 빠르다.
-	스레드 간 통신에 별도의 자원을 이용하지 않고도, 전역변수 공간이나 힙 영역을 통해 데이터를 주고받을 수 있다.
-	스택을 제외한 모든 영역이 메모리를 공유하므로 통신 부담이 적다.

### 멀티 스레딩의 문제점
-	Context switching, 동기화 등의 이유 때문에 싱글 코어 멀티 스레딩은 스레드 생성 시간이 오히려 오버헤드로 작용해 단일 스레드보다 느리다.
-	공유하는 자원에 동시에 접근하는 경우, 프로세스와 달리 스레드는 데이터와 힙 영역을 공유하기 때문에 어떤 스레드가 다른 스레드에서 사용 중인 변수나 자료구조에 접근하여 엉뚱한 값을 읽어오거나 수정할 수 있다. 따라서 동기화가 필요하다.
-	운영체제의 지원이 필요하다.
-	프로그래밍 난이도가 높다. 또한, 스레드 수만큼 자원을 많이 사용한다.

### 멀티 스레드 vs 멀티 프로세스
+ 멀티 스레드
  + 하나의 스레드에 문제가 생기면 전체 프로세스에 영향을 끼칠 수 있다.
  + 멀티 프로세스보다 적은 메모리 공간 차지, context witching 시 비용이 덜 들어 응답시간이 그만큼 빠르다.
  + 프로세스의 스택을 제외한 다른 자원을 공유하는 만큼 이로 인한 동기화 문제라는 단점이 존재한다.
+ 멀티 프로세스
  + 하나의 프로세스가 죽더라도 다른 프로세스에 영향을 끼치지 않는다.
  + 멀티 스레드보다 많은 메모리 공간과 CPU 시간을 차지하고, context switching 시 여러 무거운 작업들을 동반하며 비용이 많이 소요되어 응답 속도가 느려지는 단점이 존재한다.
<br/>
  + 대상 시스템의 특징에 따라 적합한 동작 방식을 선택하고 적용해야 한다.

## 스케줄러
한정적인 메모리를 프로세스가 효율적으로 사용할 수 있도록 작업을 할당시켜주는 역할을 한다.<br/>
프로세스를 스케줄링 하기 위한 Queue에는 세 가지 종류가 존재한다.
-	Job Queue : 현재 시스템 내에 있는 모든 프로세스의 집합
-	Ready Queue : 현재 메모리 내에 있으면서 CPU를 잡아서 실행되기를 기다리는 프로세스의 집합
-	Device Queue : Device I/O 작업을 대기하고 있는 프로세스의 집합
<br/>
각각의 Queue에 프로세스들을 넣고 빼주는 스케줄러에도 크게 세 가지 종류가 존재한다.

### 장기스케줄러(Long-term scheduler or job scheduler)
-	메모리는 한정되어 있는데 많은 프로세스들이 한꺼번에 메모리에 올라올 경우, 대용량 메모리(일반적으로 디스크)에 임시로 저장된다. 이 pool에 있는 프로세스 중 어떤 프로세스를 ready queue로 보낼 지 결정하는 역할을 한다.
-	메모리와 디스크 사이의 스케줄링을 담당
-	프로세스에 memory 및 각종 리소스를 할당
-	Degree of Multiprogramming 제어
(메모리에 여러 프로그램이 올라가는 것) 몇 개의 프로그램이 올라갈 것인지를 제어
-	프로세스의 상태 : new - ready

### 단기스케줄러(Short-term scheduler or CPU scheduler)
-	CPU와 메모리 사이의 스케줄링을 담당
-	Ready Queue에 존재하는 프로세스 중 어떤 프로세스를 running 시킬지 결정
-	프로세스레 CPU를 할당
-	프로세스의 상태 : ready - running - waiting - ready

### 중기스케줄러(Medium-term scheduler or Swapper)
-	여유 공간 마련을 위해 프로세스를 통째로 메모리에서 디스크로 쫓아냄
-	프로세스에게서 memory를 deallocate
-	현 시스템에서 메모리에 너무 많은 프로그램이 올라가는 것을 조절하는 스케줄러
-	프로세스의 상태 : ready - suspended

## CPU 스케줄러
메모리에 올라온 프로세스들 중 어떤 프로세스를 먼저 처리할지 순서를 정하는 것이다.<br/>
Ready Queue에 있는 프로세스들 중에 누구에게 CPU를 할당해 줄 것인지 정한다.

#### 비선점 스케줄링
-	어떤 프로세스가 CPU를 점유하고 있다면 해당 프로세스의 작업이 완료될 때까지 다른 프로세스가 강제로 CPU를 빼앗아 사용할 수 없는 스케줄링 기법이다.
-	종류 : FCFS, SJF, 우선순위, HRN, 기한부 알고리즘

#### 선점 스케줄링
-	하나의 프로세스가 CPU를 점유하고 있을 때, 우선순위가 높은 다른 프로세스가 CPU를 강제로 빼앗아 사용할 수 있는 스케줄링 기법이다.
-	종류 : Round Robin, SRT, 선점 우선순위, 다단계 큐, 다단계 피드백 큐 알고리즘

### FCFS(First Come First Served)
-	비선점 스케줄링
-	먼저 요청한 프로세스를 먼저 처리하는 방식
-	모든 프로세스의 우선순위가 동일하고, 프로세스의 CPU 처리 시간을 따로 고려하지 않기 때문에 매우 단순하고 공평한 방법이다.
-	CPU 처리 시간이 길지만 덜 중요한 작업이, CPU 처리 시간이 짧고 더 중요한 작업을 기다리게 할 수도 있다. - 이를 콘보이 효과라고 한다.
-	콘보이 효과 : CPU를 매우 오래 사용하는 프로세스가 도착하게 되면, 다른 프로세스가 CPU를 사용하는 데 기다리는 대기 시간이 매우 커지는 현상

### SJF(Shortest - Job - First)
-	비선점 스케줄링
-	CPU 작업 시간이 가장 짧은 프로세스 순으로 스케줄링 (빨리 끝나는 것부터 처리)
-	늦게 도착하더라도 CPU 처리 시간이 앞에 대기중인 프로세스보다 짧으면 먼저 CPU를 할당받을 수 있다. - 콘보이 효과 완화
-	모든 방식을 통틀어 평균 대기 시간을 가장 짧게 만드는 방식으로 알려져 있다.
-	CPU 처리 시간이 긴 프로세스의 경우 처리 시간이 짧은 프로세스가 계속해서 들어오면 Ready Queue에서 무한정 CPU를 기다려야 하는 상황이 발생할 수 있다. - 이를 기아(starvation) 현상이라고 한다.
-	기아(starvation) 현상 : 자신보다 우선순위가 높은 프로세스 때문에 오랫동안 CPU 할당을 받지 못하고 무한정 기다리는 현상

### SRTF(Shortest Remaining Time First)
-	SJF 방식을 선점형 스케줄링 방식으로 변경한 기법
-	CPU를 점유중인 프로세스보다 남은 CPU 처리 시간이 짧은 프로세스가 Ready Queue에 들어올 경우 새로 들어온 프로세스가 CPU를 점유할 수 있다.
-	어떤 알고리즘보다 평균 대기 시간이 가장 짧은 알고리즘이지만, 기본적으로 선점형 방식이기 때문에 잦은 context switching이 일어나고 그에 따른 오버헤드가 커진다.
-	기아(starvation) 현상이 더 심각하게 발생할 수 있다.
-	CPU 처리 시간은 예측하기가 힘들기 때문에 실제로 사용되기 어렵다

### Priority Scheduling
-	우선순위가 높은 프로세스에게 먼저 CPU를 할당하는 방식
-	선점, 비선점 둘 다 가능

### Round Robin
-	선점 스케줄링
-	RR 스케줄링이라고도 한다.
-	시분할 시스템에서 사용
-	FCFS 스케줄링 방식에 선점 스케줄링 방식과 Time Quantum 개념을 추가한 방식이다.
-	프로세스에게 각각 동일한 CPU 할당 시간(타임 슬라이스, quantum)을 부여해서 그 시간 동안만 CPU를 이용하게 한다.
-	어떤 프로세스가 CPU를 사용한 시간이 Time Quantum만큼 지나면 이 프로세스로부터 CPU 자원을 회수하고, 이 프로세스를 Ready Queue의 가장 뒤로 보낸다.
-	모든 프로세스가 최초 응답 시간을 빠르게 보장받을 수 있다는 큰 장점이 있고 자연스럽게 콘보이 효과 역시 줄어든다.

## 동기와 비동기 및 Sync와 Async 차이 (블로킹과 논블로킹)
-	제어권 : 제어권은 자신(함수)의 코드를 실행할 권리 같은 것이다. 제어권을 가진 함수는 자신의 코드를 끝까지 실행한 후, 자신을 호출한 함수에게 돌려준다.
-	결과값을 기다린다는 것 : A 함수에서 B 함수를 호출했을 때, A 함수가 B 함수의 결과값을 기다리느냐의 여부를 의미한다.

#### 동기(Synchronous)
-	동시에 일어난다는 의미이다.
-	작업을 동시에 수행하거나, 동시에 끝나거나, 끝나는 동시에 시작
-	함수를 호출하는 곳에서 호출되는 함수가 결과를 반환할 때까지 기다린다.
-	작업 완료 여부를 계속해서 확인한다.

#### 비동기(Asynchronous)
-	동시에 일어나지 않음을 의미한다.
-	시작, 종료가 일치하지 않으며, 끝나는 동시에 시작을 하지 않음
-	함수를 호출하는 곳에서 결과를 기다리지 않고, 다른 함수(callback)에서 결과를 처리한다.
-	작업 완료 여부를 확인하지 않는다.

#### 블로킹(Blocking)
-	특정 작업이 실행 요청을 받아서 실행하는 동안 다른 작업은 진행하지 못하고 대기하는 방식을 의미한다.
-	제어권이 호출된 함수에게 넘어가서 호출된 함수 내에서 작업이 모두 끝난 후 값이 리턴되고, 호출한 함수에게 다시 제어권이 넘어온다.
-	작업이 완료된 후 새로운 작업을 수행할 수 있다.
-	작업이 순차적으로 이루어지므로 작업 흐름을 쉽게 이해할 수 있다는 장점이 있다.
-	블로킹이 이루어지는 동안 하드웨어 리소스를 효율적으로 이용하지 못한다는 단점이 있고, 특히 블로킹이 일어나는 작업이 오래 걸리는 작업인 경우 이러한 단점은 더욱 부각된다.

#### 논블로킹(Non-Blocking)
-	특정 작업이 이미 수행중이어도, 그것과 상관없이 바로 다른 작업을 수행시키는 방식을 의미한다.
-	제어권이 계속 호출한 함수에 있기 때문에 작업의 완료여부와 관계없이 새로운 작업을 수행할 수 있다.
-	작업 흐름이 복잡해져서 이해가 쉽지 않다는 단점이 있다.
-	리소스가 낭비되는 시간이 없으므로, 하드웨어 리소스를 효율적으로 이용할 수 있다.

## 동시성 문제 
동시성 문제는, 두 개 이상의 세션이 공통된 자원에 대해 모두 읽고 쓰는 작업(Read - Write)을 할 때 발생하는 문제를 뜻한다.
### Critical Section(임계영역)
-	한 번에 하나의 프로세스만 액세스 할 수 있는 코드영역을 의미한다.
-	둘 이상의 프로세스가 동시에 접근할 수 없다.
-	만약 여러 프로세스가 동시에 임계영역에 접근하려고 한다면 Race Condition이 발생한다.

### RaceCondition
-	두 개 이상의 프로세스가 공유 자원을 병행적으로 읽거나 쓰는 상황을 말하며, 공유 자원 접근 순서에 따라 실행 결과가 달라지는 상황을 말한다.
### Deadlock(교착상태)
-	프로세스가 자원을 얻지 못해 다음 처리를 하지 못하는 상태이다.
-	둘 이상의 프로세스가 각자 공유 자원을 할당 받은 후 다음 처리를 위해 다른 공유 자원을 할당 받아야할 때, 각자 필요한 자원이 상대방에게 할당 되어있는 경우 프로세스들이 다음 처리를 위한 공유 자원을 획득하기 위해 서로 무한정 대기하는 상태이다.

### Deadlock 발생 조건 
-	상호배제 (Mutual Excusion) : 한 번에 하나만 해당 자원을 사용할 수 있다. 사용 중인 자원을 다른 프로세스가 사용하려면 요청한 자원이 해제될 때까지 기다려야 한다.
-	점유 대기 (Hold and Wait) : 자원을 최소한 하나만 보유하고, 다른 프로세스에 할당된 자원을 점유하기 위해 대기하는 프로세스가 존재해야 한다.
-	비선점 (Non Preemptive) : 이미 할당된 자원을 강제로 빼앗을 수 없다.
-	순환 대기 (Circular wait) : 대기 프로세스의 집합이 순환 형태로 자원을 대기하고 있어야 한다.

### Deadlock 해결 방법  
+ 교착 상태 예방
  + 교착 상태가 발생하기 전에 미리 조치를 취하는 방식으로, 교착 상태 발생 조건 중 하나를 제거함으로써 해결한다.
  + 자원의 상호배제 조건 방지 : 모든 자원을 공유 허용
  + 점유와 대기 조건 방지 : 모든 자원에 대해 선점 허용
  + 비선점 조건 방지 : 필요 자원을 한 번에 모두 할당하기
  + 순환 대기 조건 방지 : 자원에게 순서 부여를 통해 프로세스 순서의 증가 방향으로만 자원 요청

+ 교착 상태 회피
  + 프로세스가 자원을 요구할 때, 시스템은 자원을 할당한 후에도 안정 상태로 남아있는가를 확인하여 교착 상태를 회피하는 방법

+ 교착 상태 탐지
  + Deadlock이 발생하면 빠르게 발견하고 문제를 해결하는 것

+ 교착 상태 회복
  + 교착 상태를 일으킨 프로세스를 종료하거나 할당된 자원을 해제하면서 회복

## 메모리 관리 전략
-	메모리 용량이 증가함에 따라 프로그램의 크기 또한 계속 증가하고 있기 때문에 메모리는 언제나 부족하다.
-	메모리 관리 전략은 제한된 물리 메모리의 효율적인 사용과 메모리 참조 방식을 제공하기 위한 전략이다.

### Paging(페이징)
-	메모리 공간이 연속적으로 할당되어야 한다는 제약조건을 없애는 메모리 관리 전략
-	논리 메모리는 고정 크기의 페이지, 물리 메모리는 고정 크기의 프레임 블록으로 나누어 관리
-	프로세스가 사용하는 공간을 논리 메모리에서 여러 개의 페이지로 나누어 관리하고, 개별 페이지는 순서에 상관없이 물리 메모리에 있는 프레임에 매핑되어 저장
-	MMU(Memory Management Unit)의 재배치 레지스터 방식을 활용해 CPU가 마치 프로세스가 연속된 메모리에 할당된 것처럼 인식하도록 함
-	Page에 여유 공간이 남게 되는 경우가 많기 때문에 내부 단편화가 발생하는 단점

### Segmentation(세그멘테이션)
-	페이징 기법과 반대로 논리 메모리와 물리 메모리를 같은 크기의 블록이 아닌, 서로 다른 크기의 논리적 단위인 세그먼트로 분할
-	서로 다른 크기의 세그먼트들이 적재되고 제거되다보면 빈 공간이 많은 수의 작은 조각으로 나뉘어 사용하지 못하기 때문에 외부 단편화 문제를 해결하지 못하는 단점

#### 세그멘테이션 페이징 혼용 기법
-	페이징과 세그메테이션을 혼용해 단편화를 최대한 줄이려는 전략
-	프로세스를 세그먼트(논리적 기능 단위)로 나눈 다음 세그먼트를 다시 페이지 단위로 나누어 관리
-	매핑 테이블을 두 번 거쳐야 하므로 속도가 느려짐

## 가상 메모리
-	물리 메모리 크기의 한계를 극복하기 위해 나온 기술
-	어떤 프로세스가 실행될 때 메모리에 해당 프로세스 전체가 올라가지 않더라도 실행이 가능하다는 점에 착안하여 고안되었음
-	가상 메모리의 핵심은 필요한 부분만 메모리에 적재(부분적재)하는 것 - 프로세스를 실행할 때, 실행에 필요한 부분만 메모리에 올린다.

### 가상 주소 공간
-	가상 주소 공간은 각 프로세스당 주어지는 논리적인 공간이다.
-	가상 주소 공간의 크기는 물리 메모리(RAM)의 크기와는 독립적이며, 레지스터 크기에 종속적이다.

### 프로세스간의 페이지 공유
-	시스템 라이브러리가 여러 프로세스들 사이에 공유될 수 있도록 한다. 각 프로세스들은 공유 라이브러리를 자신의 가상 주소 공간에 두고 사용하는 것처럼 인식하지만, 라이브러리가 올라가 있는 물리 메모리 페이지들은 모든 프로세스에 공유되고 있다.
-	프로세스들이 메모리를 공유하는 것을 가능하게 하고, 프로세스들은 공유 메모리를 통해 회신할 수 있다. 이 또한, 각 프로세스들은 각자 자신의 주소 공간처럼 인식하지만, 실제 물리 메모리는 공유되고 있다.
-	logical address는 physical address로부터 분리된다.
-	fork()를 통한 생성 과정에서 페이지들이 공유되는 것을 가능하게 한다.

### Demand Paging(요구 페이징)
-	프로그램 실행 시작 시에 프로그램 전체를 디스크에서 물리 메모리에 적재하는 대신, 초기에 필요한 것들만 적재하는 전략
-	CPU가 해당 페이지를 요구할 때까지 그 페이지를 메모리에 올리지 않는다.
-	한 번도 접근되지 않는 페이지는 물리 메모리에 전혀 적재되지 않는다.
-	페이지 부재(page fault)가 발생하면 그 때 트랩을 걸어 해당 페이지를 적재한다.

### Page fault trap(페이지 부재 트랩)
-	요구 페이징에서는 프로그램에 대한 모든 내용이 물리 메모리에 올라오지 않기 때문에 메모리에 없는 페이지에 접근하려 할 때 페이지 부재 트랩이 발생한다.
-	페이지 부재 트랩이 발생하면 원하는 페이지를 저장 장치에서 가져오게 되고, 만약 물리 메모리가 가득 차 있는 상태라면 페이지 교체가 이루어진다.
+ 페이지 부재 트랩 처리 과정
1.	페이지 부재 트랩 발생
2.	디스크에서 해당 페이지를 찾음
3.	빈 페이지 프레임을 찾음
4.	페이지 교체 알고리즘을 통해 Victim 페이지 선택
5.	Victim 페이지를 디스크에 저장
6.	비워진 페이지 프레임에 새 페이지를 읽어옴
7.	재시작

## 페이지 교체
페이징 기법으로 메모리를 관리하는 운영체제에서 필요한 페이지가 주기억장치에 적재되지 않았을 시(페이지 부재) 어떤 페이지 프레임을 선택하여 교체할 것인지 결정하는 방법
-	프레임 : 물리 메모리를 일정한 크기로 나눈 블록
-	페이지 : 가상 메모리를 일정한 크기로 나눈 블록

### FIFO 페이지 교체
-	FIFO, First In First Out
-	선입 선출
-	물리 메모리에 올라온 페이지 순으로 페이지 교체시점에 나가게 됨
-	큐를 이용해 쉽게 구현이 가능
-	오히려 페이지 부재율을 높일 수 있으며, Belady의 모순이 발생 가능
-	Belady의 모순 : 페이지 프레임의 개수를 늘려도 페이지 부재가 줄어들지 않는 모순 현상

### 최적 페이지 교체(Optimal Page Replacement)
-	OPT, Optimal Page Replacement
-	가장 오랫동안 사용되지 않을 페이지를 찾아 교체하는 것
-	낮은 페이지 부재율을 보장하지만, 구현이 어려움

### LRU 페이지 교체(LRU Page Replacement)
-	Least – Recently – Used Page Replacement
-	최적 페이지 교체에 근사한 알고리즘
-	가장 오랫동안 사용되지 않은 페이지를 선택해 교체
-	FIFO보다 낮은 페이지 부재율을 보장
-	우선순위 큐, Double Linked Queue & HashTable로 구현 가능

### LFU 페이지 교체(LFU Page Replacement)
-	Least – Frequently – Used Page Replacement
-	참조 횟수가 가장 작은 페이지를 교체
-	참조 횟수가 높을수록 앞으로 계속 참조할 것이라는 가정에 기인
-	어떤 프로세스가 특정 페이지를 집중적으로 사용하다가 다른 페이지를 집중적으로 사용하게 되면 초기 가정을 만족하지 못함

### MFU 페이지 교체(MFU Page Replacement)
-	Most – Frequently – Used Page Replacement
-	참조 횟수가 가장 많은 페이지를 교체
-	참조 횟수가 낮을수록 최근에 페이지 프레임에 올라왔고, 앞으로 사용될 가능성이 많다는 가정에 기인

## 기타 
### 동시성과 병령성 차이
+ 동시성 프로그래밍
  + 동시에 실행되는 것처럼 보이는 것
  + 싱글 코어(멀티 코어에서도 가능)에서 멀티 스레드를 동작 시키기 위한 방식
  + 여러 개의 스레드를 번갈아 가면서 실행되는 방식

+ 병렬성 프로그래밍
  + 물리적으로 동시에 정확히 실행되는 것
  + 멀티 코어에서 멀티 스레드를 동작시키기 위한 방식
  + 데이터 병렬성과 작업 병렬성으로 구분된다.
  + 데이터 병렬성 : 전체 데이터를 나누어 서브 데이터로 나눈 뒤, 서브 데이터들을 병렬 처리해서 작업을 빠르게 수행하는 방법
  + 작업 병렬성 : 서로 다른 작업을 병렬 처리하는 것을 말함

### 은행원 알고리즘 
-	교착상태 회피 알고리즘
-	교착상태에 빠질 가능성이 있는지, 없는지를 판단하기 위해 상태를 ‘안전 상태’와 ‘불안전 상태’로 나눈다. 그리고 운영체제는 안전 상태를 유지할 수 있는 요구만 수락해주고, 나머지 요구들은 안전 상태를 만족할 때까지 계속 거절한다.
-	안전 상태(Safe State) : 시스템이 교착 상태를 일으키지 않으면서 각 프로세스가 요구한 최대 요구량만큼 필요한 자원을 할당해줄 수 있는 상태. 안전순서열이 존재해야 한다.
-	불안전 상태(Unsafe State) : 안전순서열이 존재하지 않는 상태. 불안전 상태는 교착상태이기 위한 필요조건. 불안전 상태라 해서 무조건 교착상태가 발생하는 것이 아니라, 교착상태는 불안전 상태에서만 발생한다는 것이다.
-	은행원 알고리즘의 이름은 은행이 최소한 한 명에게 대출해줄 수 있는 금액을 항상 보유하고 있어야 한다는 개념에서 나온 것이다.<br/>

+ 은행원 알고리즘이 제대로 수행되기 위해 필요한 3가지
1.	MAX : 각 고객들이 얼마나 최대로 돈을 요구할지 = 각 프로세스가 자원을 최대로 얼마까지 요청할 수 있는지
2.	Allocated : 각 고객들이 현재 빌린 돈이 얼마인지 = 각 프로세스가 현재 보유하고 있는 자원이 얼마인지
3.	Available : 은행이 보유하고, 빌려줄 수 있는 돈은 얼마인지 = 시스템이 자원을 얼마나 보유하고 있는지
